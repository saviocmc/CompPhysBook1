\chapter{Introduction to C++ and Fortran}\label{chap:numanalysis}

\abstract{This chapters aims at catching two birds with a stone;  to introduce to you essential features of the programming languages
C++ and Fortran with a brief reminder on Python specific topics, and to stress problems like
overflow, underflow, round off errors and eventually loss of precision due to the finite amount 
of numbers a computer can represent.  
The programs we discuss are tailored to these aims. You will also learn to }

\section{Getting Started}



In programming languages
we encounter data entities such
as constants, variables, results of evaluations of functions
etc. Common to these objects is that they can be represented
through the type concept. There are intrinsic types and derived
types. Intrinsic types are provided by the programming language
whereas derived types are provided by the programmer.
If one specifies the type to be for example \verb?INTEGER (KIND=2)? 
for Fortran \footnote{Our favoured display mode for Fortran statements
will be capital letters for language statements and low key
letters for user-defined statements. Note that Fortran
does not distinguish between capital and low key letters while
C++ does.}
or\verb? short int/int  ? in C++,
the programmer selects a particular date type with 2 bytes
(16 bits) for every item of the class
\verb? INTEGER (KIND=2)? or\verb? int?. Intrinsic types come
in two classes, numerical (like integer, real or complex)
and non-numeric (as logical and character).
The general form for declaring  variables is 
\verb? data type name of variable?
and Table \ref{tab:listofdeclar} 
lists the standard variable declarations of C++ and Fortran 
(note well that there be may compiler and machine differences from the table below).
An important aspect when declaring variables is their
region of validity.
Inside a function we define a a variable through the expression 
\verb?int var? or \verb? INTEGER :: var? . The question is 
whether this variable is available in
other functions as well, moreover where is 
\verb?var? initialized and finally, if we call the function where
it is declared, is the value conserved from one call to the other?
\begin{table}[hbtp]
\caption{Examples of variable declarations for C++ and Fortran . We reserve capital
letters for Fortran  declaration statements throughout this text, although Fortran  is
not sensitive to upper or lowercase letters. Note that there are machines which allow for more than 64 bits 
for doubles. The ranges listed here may therefore vary. \label{tab:listofdeclar} }
\begin{center}
\begin{tabular}{lcl}\hline \hline
\hspace*{\fill} type in C++ and Fortran  \hspace*{\fill}
&\hspace*{\fill} bits \hspace*{\fill}
&\hspace*{\fill} range \hspace*{\fill} \\ \hline
& & \\[-2mm]
int/INTEGER (2) & 16 & $-32768$ to 32767\\
unsigned int & 16 & 0 to 65535\\
signed int & 16 & $-32768$ to 32767\\
short int & 16 & $-32768$ to 32767\\
unsigned short int & 16 & 0 to 65535\\
signed short int & 16 & $-32768$ to 32767\\
int/long int/INTEGER(4) & 32 & $-2147483648$ to 2147483647\\
signed long int & 32 & $-2147483648$ to 2147483647\\
float/REAL(4) & 32 & $10^{-44}$ to $10^{+38}$\\
double/REAL(8) & 64 & $10^{-322}$ to $10e^{+308}$\\\hline\hline
\end{tabular}
\end{center}
\end{table}

Both C++ and Fortran  operate with several types of 
variables and the answers to these questions depend on how
we have defined for example an integer via the statement {\tt int var}. 
Python on the other hand does not use variable or function types (they are not explicitely written),
allowing thereby for a better potential for reuse of the code. 

The following list may help
in clarifying the above points:
\begin{center}
\begin{tabular}{|ll|} \hline
&\\[-3mm]
type of variable & \hspace*{\fill}validity \hspace*{\fill}\\ 
&\\[-3mm] \hline
&\\[-3mm]
local variables & 
\begin{minipage}[t]{0.6\textwidth}
defined within a function, only available within the scope of the function.
 \vspace*{2mm}\end{minipage}\\
formal parameter &
\begin{minipage}[t]{0.6\textwidth}
If it is defined within a function it is only available within that specific
function.
\vspace*{2mm}\end{minipage}\\
global variables &
\begin{minipage}[t]{0.6\textwidth}
Defined outside a given function, available for all 
functions from the point where it is defined.
\vspace*{2mm}\end{minipage}\\
\hline
\end{tabular}
\end{center}
In Table~\ref{tab:intr-tab1} we show a list of some of the most used
language statements in Fortran and C++.
\begin{table}[hbtp]
\label{tab:intr-tab1}
\begin{tabular}{ll}\hline\hline\\
{\bf Fortran } & {\bf C++}\\ \hline
\multicolumn{2}{c}{{\bf Program structure}}\\
PROGRAM something & main ()\\
FUNCTION something(input) & double (int) something(input)\\
SUBROUTINE something(inout)\\
\multicolumn{2}{c}{{\bf Data type declarations} }\\
REAL (4) x, y & float x, y;\\
REAL(8) :: x, y & double x, y;\\
INTEGER :: x, y & int x,y;\\
CHARACTER :: name & char name;\\
REAL(8), DIMENSION(dim1,dim2) :: x& double x[dim1][dim2];\\
INTEGER, DIMENSION(dim1,dim2) :: x& int x[dim1][dim2];\\
LOGICAL :: x\\  \hline
TYPE name &   struct name \{ \\
declarations   & declarations;\\
END TYPE name & \}\\ \hline
POINTER :: a&   double (int)  *a;\\
ALLOCATE & new;\\
DEALLOCATE & delete;\\\hline
\multicolumn{2}{c}{{\bf Logical statements and control structure}}\\
IF ( a == b) THEN&   if ( a == b) \\
   b=0  &    \{ b=0;\\
ENDIF   &           \}\\ \hline
DO WHILE (logical statement) &  while (logical statement) \\
do something   &               \{do something \\
ENDDO          &                \}\\  \hline
IF ( a$ >=$ b ) THEN &         if ( a $>=$ b) \\
 b=0   &                      \{  b=0;\\
ELSE  &                       else \\
a=0 &                         a=0; \}\\
ENDIF & \\\hline
SELECT CASE (variable) &      switch(variable)\\
CASE (variable=value1)&       \{ \\
do something             &     case 1: \\
CASE ($\dots$)          & variable=value1;\\
$\dots$  &              do something; \\
&                       break;\\
END SELECT               & case 2:\\
&                       do something; break; $\dots$\\
&                       \}\\ \hline
DO i=0, end, 1  &      for( i=0; i$<=$ end; i++)\\
do something  &        \{ do something ; \\
ENDDO  &               \}\\\hline\hline
\hline\end{tabular}\caption{Elements of programming syntax.}\end{table}

In addition, both C++ and Fortran  allow for complex variables.
In Fortran  we would declare a complex variable as
{\tt COMPLEX (KIND=16):: x, y} which refers to a double with
word length of 16 bytes. In C++ we would need to include a complex
library through the statements

\begin{lstlisting}
#include <complex>
complex<double> x, y;
\end{lstlisting}
We will discuss the above declaration \verb? complex<double> x,y;? in
more detail in chapter \ref{chap:differentiate}. 

\subsection{Scientific hello world}
Our first  programming encounter is the 'classical' one, found in almost every
textbook on computer languages, the 'hello world' code, here in a scientific disguise. 
We present first the C version.
%\begin{lstlisting}[title={programs/chapter2/program1.cpp}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program1.cpp}}]
/* comments in C begin like this and end with */
#include <stdlib.h> /* atof function */
#include <math.h>   /* sine function */
#include <stdio.h>  /* printf function */

int main (int argc, char* argv[])
{
  double r, s;        /* declare variables */
  r = atof(argv[1]);  /* convert the text argv[1] to double */
  s = sin(r);
  printf("Hello, World! sin(%g)=%g\n", r, s);
  return 0;           /* success execution of the program */
}
\end{lstlisting}

The compiler must see a declaration of a function before you can 
call it (the compiler checks the argument and return types). 
The declaration of library functions appears 
in so-called header files that must be included in the program, for example
\verb?#include <stdlib.h?.

We call three functions\verb? atof, sin, printf? 
and these are declared in three different header files. 
The main program is a function called main 
with a return value set to an integer,  returning 0 if success. 
The operating system stores the return value, 
and other programs/utilities can check whether 
the execution was successful or not. 
The command-line arguments are transferred to the main function through  the statement
\begin{lstlisting}
int main (int argc, char* argv[])
\end{lstlisting}
The integer\verb? argc? stands for the number of command-line arguments, set to
one in our case, while  
\verb? argv? is a vector of strings containing the command-line arguments 
with   \verb? argv[0]? containing  the name of the program 
and\verb? argv[1]?,\verb? argv[2]?, ... are the command-line args, i.e., the number of 
lines of input to the program.  

This means that we would run the programs as 
\verb?mhjensen@compphys:./myprogram.exe 0.3?.  The name of the program enters \verb? argv[0]? while the text string $0.2$ enters \verb? argv[1]?. Here we define a floating point variable, see also below, through the keywords\verb? float? for single precision real numbers and  \verb? double? for double precision.  The function\verb? atof?  transforms a text \verb? (argv[1])? to a float.  The sine function is declared in math.h, a library which is not automatically included and needs to be linked when computing an executable file.

With the command\verb? printf? we obtain a formatted printout.
The\verb? printf? syntax is used for formatting output 
in many C-inspired languages (Perl, Python, awk, partly C++). 

In C++ this program can be written as 

\begin{lstlisting}
// A comment line begins like this in C++ programs
using namespace std;
#include <iostream>
#include <cstdlib>
#include <cmath>
int main (int argc, char* argv[])
{
//  convert the text argv[1] to double using atof: 
  double r = atof(argv[1]); 
  double s = sin(r);
  cout << "Hello, World! sin(" << r << ")=" << s << endl;
// success 
  return 0;  
}
\end{lstlisting}
We have replaced the call to\verb? printf? with the standard C++ function
\verb? cout?. The header file\verb? iostream? is then needed.
In addition, we don't need to 
declare variables like $r$ and $s$  at the beginning of the program. 
I personally prefer
however to declare all variables at the beginning of a function, as this
gives me a feeling of greater readability.
Note that we have used the declaration \verb?using namespace std;?. Namespace is a 
way to collect 
all functions defined in C++ libraries. If we omit this declaration on top of the program
we would have to add the declaration \verb?std? in front of  
\verb?cout? or \verb?cin?.  Our program would then read
\begin{lstlisting}
// Hello world code without using namespace std
#include <iostream>
#include <cstdlib>
#include <cmath>
int main (int argc, char* argv[])
{
//  convert the text argv[1] to double using atof: 
  double r = atof(argv[1]); 
  double s = sin(r);
  std::cout << "Hello, World! sin(" << r << ")=" << s << endl;
// success 
  return 0;  
}
\end{lstlisting}

Another feature which is worth noting is that we have skipped exception handlings here.
In chapter \ref{chap:differentiate} we discuss examples that test our input from the command
line.  But it is easy to add such a feature, as shown in our modified hello world program
\begin{lstlisting}
// Hello world code with exception handling
using namespace std;
#include <cstdlib>
#include <cmath>
#include <iostream>
int main (int argc, char* argv[])
{
// Read in output file, abort if there are too few command-line arguments
    if( argc <= 1 ){
      cout << "Bad Usage: " << argv[0] <<
      " read also a number on the same line, e.g., prog.exe 0.2" << endl;
      exit(1);   //  here the program stops.
    }
//  convert the text argv[1] to double using atof: 
  double r = atof(argv[1]); 
  double s = sin(r);
  cout << "Hello, World! sin(" << r << ")=" << s << endl;
// success 
  return 0;  
}
\end{lstlisting}
Here we test that we have more than one argument. If not, the program stops and writes to screen
an error message. Observe also that we have included the mathematics library via the 
\verb? #include <cmath>?  declaration.



To run these programs, you need first to compile and link
them in order to obtain an executable file under operating systems like  e.g., 
UNIX or Linux. 
Before we proceed we give therefore examples on how to obtain an
executable file under Linux/Unix. 

In order to obtain an executable file for a C++ program, the following 
instructions under Linux/Unix can be used
\begin{svgraybox}
\begin{verbatim}
c++ -c -Wall myprogram.c
c++ -o myprogram myprogram.o
\end{verbatim}
\end{svgraybox}
where the compiler is called through the command \verb$c++$. The compiler
option -Wall means that a warning is issued in case of non-standard
language. The executable file is in this case \verb$myprogram$. The option
\verb$-c$ is for compilation only, where the program is translated into machine code,
while the \verb$-o$ option links the produced object file \verb$myprogram.o$ 
and produces the executable \verb$myprogram$ .

The corresponding Fortran  code is 
\lstset{language=[90]Fortran}
%\begin{lstlisting}[title={programs/chapter2/program1.f90}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/Fortran/program1.f90}}]
PROGRAM shw
   IMPLICIT NONE
   REAL (KIND =8) :: r         ! Input number
   REAL (KIND=8)  :: s         ! Result

!  Get a number from user
   WRITE(*,*) 'Input a number: '
   READ(*,*) r
!  Calculate the sine of the number
   s = SIN(r)
!  Write result to screen
   WRITE(*,*) 'Hello World! SINE of ', r, ' =', s
END PROGRAM shw
\end{lstlisting}
 The first statement must be a program statement; the last statement must have a
corresponding end program statement. 
Integer numerical variables and floating point numerical variables are distinguished. The
names of all variables must be between 1 and 31 alphanumeric characters of which the first
must be a letter and the last must not be an underscore. 
Comments begin with a ! and can be included anywhere in the program. 
Statements are written on lines which may contain up to 132 characters. 
The asterisks (*,*) following WRITE represent 
the default format for output, i.e., the output is e.g., 
written on the screen. Similarly, the READ(*,*) statement means
that the program is expecting a line input.
Note also the IMPLICIT NONE statement which we 
strongly recommend the use of. In many Fortran 77 programs one can  find
statements like IMPLICIT REAL*8(a-h,o-z), meaning
that all variables beginning with any of the above 
letters are by default floating numbers. However,
such a usage makes it hard to spot eventual errors
due to misspelling of variable names. With IMPLICIT NONE
you have to declare all variables and therefore detect
possible errors already while compiling. I recommend strongly that you declare all variables
when using Fortran.

We call the Fortran compiler (using free format) through 
\begin{svgraybox}
\begin{verbatim}
f90 -c -free myprogram.f90
f90 -o myprogram.x  myprogram.o
\end{verbatim}
\end{svgraybox}
Under Linux/Unix it is often convenient to create a
so-called makefile, which is a script which includes possible
compiling commands, in order to avoid retyping the above lines
every once and then we have made modifcations to our program.
A typical makefile for the above $cc$ compiling options is listed
below
\begin{svgraybox}
\begin{verbatim}
# General makefile for c - choose PROG =   name of given program

# Here we define compiler option, libraries and the  target
CC= c++ -Wall
PROG= myprogram

# Here we make the executable file 
${PROG} :          ${PROG}.o
                   ${CC} ${PROG}.o -o ${PROG}

# whereas here we create the object file

${PROG}.o :       ${PROG}.cpp
                  ${CC} -c ${PROG}.cpp

\end{verbatim}   
\end{svgraybox}                                            
If you name your file for 'makefile', simply type the command
{\bf make} and Linux/Unix executes all of the statements in the above
makefile. Note that C++ files have the extension .cpp

For Fortran, a similar makefile is
\begin{svgraybox}
\begin{verbatim}
# General makefile for F90 - choose PROG =   name of given program

# Here we define compiler options, libraries and the  target
F90= f90 
PROG= myprogram

# Here we make the executable file 
${PROG} :          ${PROG}.o
                   ${F90} ${PROG}.o -o ${PROG}

# whereas here we create the object file

${PROG}.o :       ${PROG}.f90
                  ${F90} -c ${PROG}.f
\end{verbatim}                                               
\end{svgraybox}

Finally, for the sake of completeness, we list the corresponding Python code
\lstset{language=python}
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/python/program1.py}}]
#!/usr/bin/env python

import sys, math
# Read in a string a convert it to a float
r = float(sys.argv[1]) 
s = math.sin(r)
print "Hello, World! sin(%g)=%12.6e" % (r,s)
\end{lstlisting}
where we have used a formatted printout with scientific notation. 
In Python we do not need to declare variables. Mathematical functions like the $\sin$ 
function are imported from the {\em math} module.  For further references to Python
and its syntax, we recommend the text of Hans Petter Langtangen \cite{langtangen2009}.
The corresponding codes in Python are available at the webpage of the course.
All programs are listed as a directory tree beginning with programs/chapterxx.  Each chapter has in turn
three directories, one for C++, one for Fortran and finally one for Python codes.
The Fortran codes in this chapter can be found in the directory programs/chapter02/Fortran.
\section{Representation of Integer Numbers}

In Fortran a 
keyword for declaration of an integer is\verb? INTEGER (KIND=n)? ,
n = 2 reserves 2 bytes (16 bits) of memory to store the integer variable
wheras n = 4 reserves 4 bytes (32 bits).  In Fortran, although it may be
compiler dependent, just declaring a variable as\verb? INTEGER ?, reserves
4 bytes in memory as default. 

In C++ keywords are\verb?short int, int, long int, long long int?. The byte-length
is compiler dependent within some limits. The GNU C++-compilers (called by gcc or g++)
assign
4 bytes (32 bits) to variables declared by\verb? int ? and\verb? long int?. 
Typical byte-lengths
 are 2, 4, 4 and 8 bytes, for the types given above.
To see how many bytes are reserved for a specific variable, C++ has a
library function called\verb? sizeof(type)? which returns the number of
bytes for\verb? type ?. 

An example of a program declaration is
%
\begin{tabbing}
%
Fortran: \hspace*{1cm}\=INTEGER (KIND=2) :: \=age\_of\_participant\\
C++:                    \>short int           \>age\_of\_participant;
\end{tabbing}
%
Note that the\verb? (KIND=2)? can be written as (2). Normally however, we will 
for Fortran programs just use the 4 bytes default assignment 
\verb? INTEGER ?.

In the above examples one bit is used to store the sign of the variable
age\_of\_participant and the 
other 15 bits are used to store the number, which then
may range from zero to $2^{15}-1=32767$.
This should definitely suffice for human lifespans.
On the other hand, if we were to classify known fossiles by age we may need
%
%
\begin{tabbing}
%
Fortran: \hspace*{1cm}\=INTEGER (4) :: \=age\_of\_fossile\\
C++:                    \> int           \>age\_of\_fossile;
\end{tabbing}
%
Again one bit is used to store the sign of the variable
age\_of\_fossile and the 
other 31 bits are used to store the number which then 
may range from zero to $2^{31}-1=2.147.483.647$.
In order to give you a feeling how integer numbers are represented
in the computer, think first of the decimal representation of
the number $417$
%
\[
   417 = 4\times 10^{2}+1\times 10^{1} + 7\times 10^{0},
\]
%
which  in binary representation becomes
%
\[
  417=a_n2^n+a_{n-1}2^{n-1}  +a_{n-2}2^{n-2}  +\dots +a_{0}2^{0},
\]
%
where the coefficients $a_k$ with $k = 0,\ldots ,n$ are zero or one. They can be
calculated through successive division by 2 and using the remainder
in each division to determine the numbers $a_n$ to $a_0$.  A given integer in
binary notation is then written as 
\[
  a_n2^n+a_{n-1}2^{n-1}  +a_{n-2}2^{n-2}  +\dots +a_{0}2^{0}.
\]
%
In binary notation we have thus
%
\[
   (417)_{10} =(110100001)_2,
\]
since we have
\[
(110100001)_2
=1\times2^8+1\times 2^{7}+0\times 2^{6}+1\times 2^{5}+0\times 2^{4}+0\times 2^{3}+0\times 2^{2}+0\times 2^{2}+0\times 2^{1}+1\times 2^{0}.
\]
To see this, we have performed the following divisions by 2
\begin{center}
%\begin{table}[hbtp]
\begin{tabular}{lcc}\hline
417/2=208  & remainder 1& coefficient of $2^{0}$ is 1\\
208/2=104  & remainder 0& coefficient of $2^{1}$ is 0\\
104/2=52  & remainder 0& coefficient of $2^{2}$ is 0\\
52/2=26  & remainder 0& coefficient of $2^{3}$ is 0\\
26/2=13  & remainder 0& coefficient of $2^{4}$ is 0\\
13/2= 6 & remainder 1& coefficient of $2^{5}$ is 1\\
6/2= 3 & remainder 0& coefficient of $2^{6}$ is 0\\
3/2= 1 & remainder 1& coefficient of $2^{7}$ is 1\\
1/2= 0 & remainder 1& coefficient of $2^{8}$ is 1\\
\hline\end{tabular}%\end{table}
\end{center}
We see that nine bits are sufficient to represent 417.
Normally we end up using 32 bits as default for integers, meaning that our number reads
\[
   (417)_{10} =(00000000000000000000000110100001)_2,
\]


A simple program which performs these operations is listed below. Here we 
employ the modulus operation (with division by 2), which in C++ is given by the \verb?a%2? operator.
In Fortran  we would call the function
\verb? MOD(a,2)? in order to obtain the remainder of a division by $2$. 
\lstset{language=c++}
%\begin{lstlisting}[title={programs/chapter2/program2.cpp}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program2.cpp}}]
using namespace std;
#include <iostream>

int main (int argc, char* argv[])
{
   int i; 
   int terms[32]; // storage of a0, a1, etc, up to 32 bits
   int number = atoi(argv[1]); 
// initialise the term a0, a1 etc
   for (i=0; i < 32 ; i++){ terms[i] = 0;}
   for (i=0; i < 32 ; i++){ 
       terms[i] = number%2;
       number /= 2;
   }
// write out results
   cout << `` Number of bytes used= '' << sizeof(number) << endl;
   for (i=0; i < 32 ; i++){ 
       cout << `` Term nr: `` << i << ``Value= `` << terms[i];
       cout << endl;
   }
  return 0;  
}
\end{lstlisting}
The C++ function \verb?sizeof? yields the number of bytes reserved for 
a specific variable. Note also the \verb?for? construct. We have reserved a 
fixed array which contains the values of $a_i$ being $0$ or $1$, the remainder
of a division by two. We have enforced the integer to be represented by 32 bits, or four
bytes, which is the default integer representation.

Note that for $417$ we need 9 bits in order to represent it in a binary notation, while a number like
the number 3 is given in an 32 bits word as
\[
  (3)_{10}= (00000000000000000000000000000011)_2.
\]
For this number  2 significant bits would be enough.



With these prerequesites in mind, it is rather obvious that
if a given integer variable is beyond the range assigned by the 
declaration statement we may encounter problems.



If we multiply two large integers
$n_1\times n_2$ and the product is too large for the bit size allocated
for that specific integer assignement, we run into an overflow problem.
The most significant bits are lost and the least significant
kept. Using 4 bytes for integer variables the result becomes
%
\[
     2^{20} \times 2^{20} =0.
\]
%
However, there are compilers or compiler options that
preprocess the program in such a way that an error message
like 'integer overflow' is produced when running the program.
Here is a small program which may cause overflow problems when
running (try to test your own compiler in order to be sure
how such problems need to be handled).
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program3.cpp}}]
// Program to calculate 2**n
using namespace std;
#include <iostream>

int main()
{
   int  int1, int2, int3;
// print to screen
   cout << "Read in the exponential N for 2^N =\n";    
// read from screen
   cin >> int2; 
   int1 = (int) pow(2., (double) int2);
   cout << " 2^N * 2^N = " << int1*int1 << "\n";
   int3 = int1 - 1;
   cout << " 2^N*(2^N - 1) = " << int1 * int3  << "\n";
   cout << " 2^N- 1 = " << int3  << "\n";
   return 0;
} 
// End: program main() 
\end{lstlisting}
If we run this code with an exponent $N=32$, we obtain the following output
\begin{svgraybox}
\begin{verbatim}
2^N * 2^N = 0
2^N*(2^N - 1) = -2147483648
2^N- 1 = 2147483647
\end{verbatim}
\end{svgraybox}
We notice that $2^{64}$ exceeds the limit for integer numbers with 32 bits.  The program returns $0$.
This can be dangerous, since the results from the operation $2^N(2^N-1)$ is obviously wrong.
One possibility to avoid such cases is to add compilation options which flag if an overflow or underflow
is reached.


\subsection{Fortran codes}

The corresponding Fortran  code is 
\lstset{language=[90]Fortran}
%\begin{lstlisting}[title={programs/chapter2/program2.f90}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/Fortran/program2.f90}}]
PROGRAM binary_integer
IMPLICIT NONE
  INTEGER  i, number, terms(0:31) ! storage of a0, a1, etc, up to 32 bits, 
! note array length running from 0:31. Fortran allows negative indexes as well.

  WRITE(*,*) 'Give a number to transform to binary notation' 
  READ(*,*) number
! Initialise the terms a0, a1 etc
  terms = 0
! Fortran takes only integer loop variables
  DO i=0, 31
     terms(i) = MOD(number,2)  ! Modulus function in Fortran
     number = number/2
  ENDDO
! write out results
  WRITE(*,*) 'Binary representation '
  DO i=0, 31
    WRITE(*,*)' Term nr and value', i, terms(i)
  ENDDO

END PROGRAM binary_integer
\end{lstlisting}
and
\lstset{language=[90]Fortran}
%\begin{lstlisting}[title={programs/chapter2/program3.f90}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/Fortran/program3.f90}}]
PROGRAM integer_exp
  IMPLICIT NONE
  INTEGER :: int1, int2, int3
  ! This is the begin of a comment line in Fortran 90
  ! Now we read from screen the variable int2
  WRITE(*,*) 'Read in the number to be exponentiated'   
  READ(*,*) int2 
  int1=2**int2
  WRITE(*,*) '2^N*2^N', int1*int1
  int3=int1-1
  WRITE(*,*) '2^N*(2^N-1)', int1*int3
  WRITE(*,*) '2^N-1', int3

END PROGRAM integer_exp
\end{lstlisting}
In Fortran the modulus division is performed by the intrinsic function \verb?MOD(number,2)?
in case of a division by $2$. The exponentation of a number is given by for example \verb?2**N?
instead of the call to the \verb?pow? function in C++.





\section{Real Numbers and Numerical Precision}

An important aspect of computational physics is 
the numerical precision involved. To design a good algorithm,
one needs to have a basic understanding of propagation
of inaccuracies and errors involved in calculations.
There is no magic recipe for dealing with underflow, overflow,
accumulation of errors and loss of precision, and only
a careful analysis of the functions involved can save
one from serious problems.

Since we are interested in the precision of the numerical
calculus, we need to understand how computers
represent real and integer numbers.
Most computers deal with real numbers in the binary system, or octal and hexadecimal,
in contrast to the decimal system that we humans 
prefer to use. 
The binary system uses 2 as the base, in much the same way that the
decimal system uses 10. Since the typical computer communicates 
with us in the decimal system, but works internally in e.g., the binary 
system, conversion procedures must be executed by the computer,
and these conversions involve hopefully only small roundoff errors

Computers are also not able to operate using real numbers 
expressed with more than a fixed number of digits,  and the  
set of values possible is only a 
subset of the mathematical integers or real numbers. 
The so-called word length we reserve for a given number
places a restriction on the precision with which a given
number is represented.
This means in turn, that for example floating numbers are always
rounded to a machine dependent precision, typically with
6-15 leading digits to the right of the decimal point. 
Furthermore,
each such set of values has a processor-dependent
smallest negative and a largest positive value. 


Why do we at all care about rounding and machine precision? 
The best way is to consider a simple example first.
In the following example we
assume that we can represent a floating number with a precision
of 5 digits only to the right of the decimal point.
This is nothing but a mere choice of ours, but mimicks
the way numbers are represented in the machine.

Suppose we wish to evaluate the function
\[
   f(x)=\frac{1-\cos{(x)}}{\sin{(x)}},
\]
for small values of $x$. If we multiply the denominator and numerator
with $1+\cos{(x)}$ we obtain the equivalent expression
\[
   f(x)=\frac{\sin{(x)}}{1+\cos{(x)}}.
\]

If we now choose $x=0.006$ (in radians) our choice of precision results in
\[
   \sin{(0.007)}\approx 0.59999\times 10^{-2},
\]
and
\[
   \cos{(0.007)}\approx 0.99998.
\]
The first expression for $f(x)$ results in
\[
   f(x)=\frac{1-0.99998}{0.59999\times 10^{-2}}=\frac{0.2\times 10^{-4}}{0.59999\times 10^{-2}}=0.33334\times 10^{-2},
\]
while the second expression results in
\[
   f(x)=\frac{0.59999\times 10^{-2}}{1+0.99998}=
\frac{0.59999\times 10^{-2}}{1.99998}=0.30000\times 10^{-2},
\]
which is also the exact result. In the first expression, due to our
choice of precision, we have  
only one relevant digit in the numerator, after the 
subtraction. This leads to a loss of precision and a wrong result due to
a cancellation of two nearly equal numbers. 
If we had chosen a precision of six leading digits, both expressions
yield the same answer.
If we were to evaluate $x\sim \pi$, then the second expression for $f(x)$ 
can lead to potential losses of precision due to cancellations of nearly
equal numbers. 


This simple example demonstrates  the loss of numerical precision due
to roundoff errors, where the number of leading digits is lost 
in a subtraction of two near equal numbers. 
The lesson to be drawn is that we cannot blindly compute a function.
We will always need to carefully analyze our algorithm in the search for
potential pitfalls. There is no magic recipe however, the only guideline
is an understanding of the fact that a machine cannot represent
correctly {\bf all} numbers. 


\subsection{Representation of real numbers}

Real numbers are stored with a decimal precision (or mantissa)
and the decimal exponent range. The mantissa contains the significant
figures of the number (and thereby the precision of the number).
A number like $(9.90625)_{10}$ in the decimal representation is given 
in a binary representation by
\[
(1001.11101)_2=1\times2^3+0\times 2^2 +0\times 2^1+1\times 2^0+1\times 2^{-1}+1\times 2^{-2}+1\times 2^{-3}+0\times 2^{-4}+1\times 2^{-5},
\]
and it has an exact machine number representation since we need  a finite number
of bits to represent this number. 
This representation is however not very practical. Rather, we prefer to use a scientific 
notation.
In the decimal system we would write a number like $9.90625$ 
in what is called the normalized scientific notation. This means 
simply that the decimal point is shifted and appropriate powers
of 10 are supplied. Our number could then be written as
\[
  9.90625=0.990625\times 10^{1},
\]
and a real non-zero number could be generalized as
\[
    x=\pm r\times 10^{{\mathrm{n}}},
\]
with a $r$ a number in the range $1/10 \le r < 1$.
In a similar way we can represent a binary number in  
scientific notation as 
\[
    x=\pm q\times 2^{{\mathrm{m}}},
\]
with a $q$ a number in the range $1/2 \le q < 1$. 
This means that the mantissa of a binary number would be represented by
the general formula
\[
(0.a_{-1}a_{-2}\dots a_{-n})_2=a_{-1}\times 2^{-1}
+a_{-2}\times 2^{-2}+\dots+a_{-n}\times 2^{-n}.
\]
In a typical computer, floating-point numbers are represented
in the way described above, but with certain restrictions
on $q$ and $m$ imposed by the available word length. 
In the machine, our
number $x$ is represented as
%
\[
    x=(-1)^s\times {\mathrm{mantissa}}\times 2^{{\mathrm{exponent}}},
\]
%
where $s$ is the sign bit, and the exponent gives the available range.
With a single-precision word, 32 bits, 8 bits would typically be reserved
for the exponent,  1 bit for the sign and 23 for the mantissa. This
means  that if we define a variable as
%
\begin{tabbing}
%
Fortran: \hspace*{1cm}\=REAL (4) :: \=size\_of\_fossile\\
C++:                    \>float      \>size\_of\_fossile;
\end{tabbing}
%
we are reserving  4 bytes in memory, with
8 bits for the exponent, 1 for the sign and  
and 23 bits for the mantissa, implying a numerical precision
to the sixth or seventh digit, since the least significant digit is
given by $1/2^{23}\approx 10^{-7}$. 
The range of the exponent goes from
$2^{-128}=2.9\times  10^{-39}$ to $2^{127}=3.4\times 10^{38}$, where 128 stems
from the fact that 8 bits are reserved for the exponent. 

A modification of the scientific notation for binary numbers is to
require that the leading binary digit 1 appears to the left of the binary point. 
In this case the representation of the mantissa $q$ would be
$(1.f)_2$ and $ 1 \le q < 2$. This form is rather useful when storing
binary numbers in a computer word, since we can always assume that the leading 
bit 1 is there. One bit of space can then be saved meaning that a 23 bits
mantissa has actually 24 bits. This means explicitely that a binary number with 23 bits 
for the mantissa reads
\[
(1.a_{-1}a_{-2}\dots a_{-23})_2=1\times 2^0+a_{-1}\times 2^{-1}
+a_{-2}\times 2^{-2}+\dots+a_{-n}\times 2^{-23}.
\]
As an example, consider the 32 bits binary number
\[
(10111110111101000000000000000000)_2,
\]
where the first bit is reserved for the sign, 1 in this case yielding a
negative sign. The exponent $m$ is given by the next 8 binary numbers
$01111101$ resulting in 125 in the decimal system. However, since the 
exponent has eight bits, this means it has  $2^8-1=255$ possible numbers in the interval
$-128 \le m \le 127$, our final
exponent is $125-127=-2$ resulting in $2^{-2}$.
Inserting the sign and the mantissa yields the final number in the decimal representation as
\[
 -2^{-2}\left(1\times 2^0+1\times 2^{-1}+
1\times 2^{-2}+1\times 2^{-3}+0\times 2^{-4}+1\times 2^{-5}\right)=(-0.4765625)_{10}.
\]
In this case we have an exact machine representation with 32 bits (actually, we need less than
23 bits for the mantissa).

If our number $x$ can be exactly represented in the machine, we call
$x$ a machine number. Unfortunately, most numbers cannot  and are thereby
only approximated in the machine. When such a number occurs as the result
of reading some input data or of a computation, an inevitable error
will arise in representing it as accurately as possible by
a machine number.

A floating number x, labelled $fl(x)$ will therefore always be represented as
\begin{equation}\label{eq:machinerep}
  fl(x) = x(1\pm \epsilon_x),
\end{equation}
with $x$ the exact number and the error $|\epsilon_x| \le |\epsilon_M|$, where
$\epsilon_M$ is the precision assigned. A number like $1/10$ has no exact binary representation
with single or double precision. Since the mantissa 
\[
1.\left(a_{-1}a_{-2}\dots a_{-n}\right)_2
\]
is always truncated at some stage $n$ due to its limited number of bits, there is only a 
limited number of real binary numbers. The spacing between every real binary number is given by the 
chosen machine precision.
For a 32 bit words this number is approximately
$ \epsilon_M \sim 10^{-7}$ and for double precision (64 bits) we have
$ \epsilon_M \sim 10^{-16}$, or in terms of a binary base
as $2^{-23}$ and $2^{-52}$ for single and double precision, respectively.  


\subsection{Machine numbers}
To understand that a given floating point number can be written as in Eq.~(\ref{eq:machinerep}),
we assume for the sake of simplicity that we work with 
real numbers with words of length 32 bits, or four bytes.
Then a given number $x$ in the binary representation can be represented as
\[
x= (1.a_{-1}a_{-2}\dots a_{-23}a_{-24}a_{-25}\dots)_2\times 2^n,
\]
or in a more compact form
\[
  x = r\times 2^n,
\]
with $ 1\le r < 2$ and $-126 \le n \le 127$ since our exponent is defined by eight bits.

In most cases there will not be an exact machine representation of the number $x$.  Our number will
be placed between two exact 32 bits machine numbers $x_{-}$ and $x_{+}$. Following the discussion of
Kincaid and Cheney \cite{kincaid} these numbers are given by
\[
x_{-}= (1.a_{-1}a_{-2}\dots a_{-23})_2\times 2^n,
\]
and
\[
x_{+}= \left((1.a_{-1}a_{-2}\dots a_{-23}))_2+2^{-23}\right)\times 2^n.
\]
If we assume that our number $x$ is closer to $x_{-}$  we have  that the absolute error is 
constrained by the relation
\[
   |x-x_{-}| \le \frac{1}{2}|x_{+}-x_{-}|=\frac{1}{2}\times 2^{n-23}=2^{n-24}. 
\]
A similar expression can be obtained if $x$ is closer to $x_{+}$.  
The absolute error conveys one type of information. However, we may have cases where two equal
absolute errors arise from rather different numbers. Consider for example the decimal
numbers $a=2$ and $\overline{a}=2.001$. The absolute error between these two numbers is $0.001$.
In a similar way, the two decimal numbers $b=2000$ and $\overline{b}=2000.001$ give exactly
the same absolute error. We note here that $\overline{b}=2000.001$ has more leading digits than
$b$.

If we compare the relative errors
\[
\frac{|a-\overline{a}|}{|a|}=1.0\times 10^{-3}, \hspace{0.5cm} \frac{|b-\overline{b}|}{|b|}=1.0\times 10^{-6}, 
\]
we see that the  
relative error in $b$ is much smaller than the relative error in $a$. We will see below that the relative error is intimately
connected with the number of leading digits in the way we approximate a real number.
The relative error
is therefore the quantity of interest in scientific work. Information about the 
absolute error is normally of little use in the absence of the magnitude
of the quantity being measured.

We define then the relative error for $x$ as
\[
   \frac{|x-x_{-}|}{|x|} \le \frac{2^{n-24}}{r\times 2^n}=\frac{1}{q}\times 2^{-24}\le 2^{-24}. 
\]
Instead of using $x_{-}$ and $x_{+}$ as the machine numbers closest to $x$, we introduce
the relative error 
\[
   \frac{|x-\overline{x}|}{|x|} \le 2^{n-24}, 
\]
with $\overline{x}$ being the machine  number closest to $x$.   
Defining 
\[
  \epsilon_x= \frac{\overline{x}-x}{x},
\]
we can write the previous inequality 
%
\[
  fl(x)= x(1+\epsilon_x)
\]  
%
where $|\epsilon_x| \leq \epsilon_M=2^{-24}$ for variables of length 32 bits.
The notation $fl(x)$ stands for the machine approximation of the number $x$.
The number $\epsilon_M$ is given by the
specified machine precision, approximately $10^{-7}$ for single and $10^{-16}$ for double
precision, respectively.  
%Suppose that we are dealing with a 32-bit word and deal with 
%single precision real number. This means that the precision is at 
%the 6-7 decimal places.
%Thus, we cannot represent all decimal numbers with an 
%exact binary representation in a computer. A typical  example is $0.1$,
%whereas $9.90625$ has an exact binary representation even with single
%precision.  

There are several mathematical operations where an eventual loss of precision  may appear. 
A subraction, especially important in the definition of numerical derivatives discussed in
chapter \ref{chap:differentiate} is one important operation. 
In the computation of derivatives we end up subtracting
two nearly equal quantities.
In case of such a subtraction $a=b-c$, we have  
\[
   fl(a)=fl(b)-fl(c) = a(1+\epsilon_a),
\]
or
%
\[ 
   fl(a)=b(1+\epsilon_b)-c(1+\epsilon_c),
\] 
%
meaning that
%
\[ 
   fl(a)/a=1+\epsilon_b\frac{b}{a}- \epsilon_c\frac{c}{a},
\]
%
and if $b\approx c$ we see that there is a potential for an increased
error in the machine representation of $fl(a)$. This is because we are subtracting two numbers of equal
size and what remains is only the least significant part of these
numbers. This part is prone to roundoff errors and if $a$ is small we
see that (with $b \approx c$)
%
\[ 
  \epsilon_a \approx \frac{b}{a}(\epsilon_b- \epsilon_c),
\]
%
can become very large.
The latter equation represents the relative error of this calculation.
To see this, we define first
the absolute error as 
\[
   |fl(a)-a|,
\]
whereas the relative error is 
\[
   \frac{ |fl(a)-a|}{a} \le \epsilon_a.
\]
The above subraction is thus
\[
   \frac{ |fl(a)-a|}{a}=\frac{ |fl(b)-f(c)-(b-c)|}{a},
\]
yielding
\[
   \frac{ |fl(a)-a|}{a}=\frac{ |b\epsilon_b- c\epsilon_c|}{a}.
\]
An interesting question is then how many significant binary bits are lost in a subtraction 
$a=b-c$  when we have $b\approx c$. The loss of precision theorem for a subtraction 
$a=b-c$ states that \cite{kincaid}: {\em if  $b$ and $c$ are positive normalized floating-point binary
machine numbers with $b > c$ and}
\begin{equation}\label{eq:lossofprecision}
2^{-r} \le 1-\frac{c}{b}\le 2^{-s},
\end{equation}
{\em then at most $r$ and at least $s$ significant binary bits are lost in the subtraction $b-c$.} 
For a proof of this statement, see for example Ref.~\cite{kincaid}.



But even additions can be troublesome, in particular if the numbers are very different in magnitude.
Consider for example the seemingly trivial 
addition $1+10^{-8}$ with 32 bits used to represent the various variables. 
In this case, the information contained
in $10^{-8}$ is simply lost in the addition. When we perform the addition, 
the computer equates first the exponents of the two numbers to be added.
For  $10^{-8}$ this has however catastrophic consequences since in order to
obtain an exponent equal to $10^0$, bits in the mantissa are shifted to the right.
At the end, all bits in the mantissa are zeros.



This means in turn that for calculations involving real numbers (if we omit the discussion on overflow
and underflow) we need to carefully understand the behavior of our algorithm, and test
all possible cases where round-off errors and loss of precision can arise.  
%
Other cases which may cause serious problems are singularities of the 
type $0/0$ which may arise from functions like $sin(x)/x$ as
$x\rightarrow 0$. Such problems may also need the restructuring
of the algorithm.

\section{Programming Examples on Loss of Precision and Round-off Errors}

\subsection{Algorithms for $e^{-x}$}
In order to illustrate the above problems, we discuss here some famous and perhaps less famous
problems, including a discussion on specific  programming features as well. 

We start by considering three possible algorithms
for computing $e^{-x}$:
\begin{enumerate}
\item by simply coding \[e^{-x}=\sum_{n=0}^{\infty}(-1)^n\frac{x^n}{n!}\]
\item or to employ a recursion relation for
\[
e^{-x}=\sum_{n=0}^{\infty}s_n=\sum_{n=0}^{\infty}(-1)^n\frac{x^n}{n!}
\]
using 
\[
s_n=-s_{n-1}\frac{x}{n},
\]
\item or to first calculate  
\[ 
\exp{x}=\sum_{n=0}^{\infty}s_n
\]
and thereafter taking the inverse 
\[
   e^{-x}=\frac{1}{\exp{x}}
\]
%
\end{enumerate}
Below we have included a small program which calculates 
\[
e^{-x}=\sum_{n=0}^{\infty}(-1)^n\frac{x^n}{n!},
\]
for $x$-values ranging from $0$ to $100$ in steps of 10. 
When doing the summation, we can always define a desired precision,
given below by the fixed value for the 
variable TRUNCATION$=1.0E-10$, so that for 
a certain value of $x>0$, there is always a value of $n=N$ 
for which the loss of precision in terminating the series at $n=N$ 
is always smaller than the next term in the series $\frac{x^{N}}{N!}$.
The latter is implemented through the while\{$\dots$\} 
statement.
\lstset{language=c++}
%\begin{lstlisting}[title={programs/chapter2/program4.cpp}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program4.cpp}}]
// Program to calculate function exp(-x)
// using straightforward summation with differing  precision
using namespace std;
#include <iostream>
// type float:  32 bits precision
// type double: 64 bits precision
#define   TYPE          double
#define   PHASE(a)      (1 - 2 * (abs(a) % 2))
#define   TRUNCATION    1.0E-10
// function declaration 
TYPE factorial(int);

int main()
{
   int   n;
   TYPE  x, term, sum;
   for(x = 0.0; x < 100.0; x += 10.0)  {
     sum  = 0.0;                //initialization
     n    = 0;
     term = 1;
     while(fabs(term) > TRUNCATION)  {
         term =  PHASE(n) * (TYPE) pow((TYPE) x,(TYPE) n) / factorial(n);
         sum += term;
         n++;
     }  // end of while() loop 
     cout << `` x ='' << x << `` exp = `` << exp(-x) << `` series = `` << sum;
     cout  << `` number of terms = " << n << endl;
   } // end of for() loop 
   return 0;
} // End: function main() 


//     The function factorial()
//     calculates and returns n!
 
TYPE factorial(int n)
{
   int  loop;
   TYPE fac;
   for(loop = 1, fac = 1.0; loop <= n; loop++)  {
      fac *= loop;
   }
   return fac;
} // End: function factorial()
\end{lstlisting}
There are several features to be noted\footnote{Note that different
compilers may give different messages and deal with overflow problems
in different ways.}. 
First, for low values of $x$, the agreement is good, 
however for larger $x$ values, we see a significant loss
of precision. Secondly, for $x=70$ we have an overflow problem,
represented (from this specific compiler) by NaN (not a number). 
The latter is easy to understand, since the calculation of a
factorial of the size $171!$ is beyond the limit set for the
double precision variable factorial. The message NaN appears since
the computer sets the factorial of $171$ equal to zero and we end
up having a division by zero in our expression for
$e^{-x}$.  
%
\begin{table}[hbtp]
\label{num-tab1}
\begin{center}
\begin{tabular}{rlrc}\\\hline
$x$&$\exp{(-x)}$&Series&Number of terms in series\\\hline
  0.0& 0.100000E+01& 0.100000E+01&    1\\
 10.0& 0.453999E-04& 0.453999E-04 &  44\\
 20.0& 0.206115E-08& 0.487460E-08&   72\\
 30.0& 0.935762E-13& -0.342134E-04 & 100\\
 40.0& 0.424835E-17& -0.221033E+01&  127\\
 50.0& 0.192875E-21& -0.833851E+05&  155\\
 60.0& 0.875651E-26& -0.850381E+09&  171\\
 70.0& 0.397545E-30&         NaN&  171\\
 80.0& 0.180485E-34&         NaN&  171\\
 90.0& 0.819401E-39 &        NaN&  171\\
100.0& 0.372008E-43&         NaN&  171\\    \hline
\end{tabular} 
\caption{Result  from the brute force algorithm for $\exp{(-x)}$.}
\end{center} 
\end{table}     



The overflow problem can be dealt with via a recurrence 
formula\footnote{Recurrence formulae,
in various disguises, either as ways to represent series or continued
fractions, are among the most commonly used forms for function approximation.
Examples are Bessel functions, Hermite and Laguerre polynomials, discussed for example in chapter \ref{chap:integrate}.}
for the terms in the sum, so that we avoid calculating factorials. 
A simple recurrence formula for our equation
\[
\exp{(-x)}=\sum_{n=0}^{\infty}s_n=\sum_{n=0}^{\infty}(-1)^n\frac{x^n}{n!},
\]
is to note that
\[
s_n=-s_{n-1}\frac{x}{n},
\]
so that instead of computing factorials, we need only to compute 
products. This is exemplified through the next program.
\lstset{language=c++}
%\begin{lstlisting}[title={programs/chapter2/program5.cpp}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program5.cpp}}]
// program to compute exp(-x) without factorials
using namespace std;
#include <iostream>
#define  TRUNCATION     1.0E-10

int main()
{
   int       loop, n;
   double    x, term, sum;

   for(loop = 0; loop <= 100; loop += 10){
     x    = (double) loop;          // initialization 
     sum  = 1.0;
     term = 1;
     n    = 1;
     while(fabs(term) > TRUNCATION){
	 term *= -x/((double) n);
	 sum  += term;
	 n++;
     } // end while loop 
     cout << ``x ='' << x << ``exp = `` << exp(-x) << ``series = `` << sum;
     cout  << ``number of terms = " << n << endl;
   } // end of for loop 
}  //    End: function main() 
\end{lstlisting}
\begin{table}[hbtp]
\label{num-tab2}
\begin{center}
\begin{tabular}{rllc}\\\hline
$x$&$\exp{(-x)}$&Series&Number of terms in series\\\hline
    0.000000&   0.10000000E+01&  0.10000000E+01&       1\\
   10.000000&   0.45399900E-04&  0.45399900E-04&      44\\
   20.000000&   0.20611536E-08&  0.56385075E-08&       72\\
   30.000000&   0.93576230E-13& -0.30668111E-04&      100\\
   40.000000&   0.42483543E-17& -0.31657319E+01&     127\\
   50.000000&   0.19287498E-21&  0.11072933E+05&     155\\
   60.000000&   0.87565108E-26& -0.33516811E+09&     182\\
   70.000000&   0.39754497E-30& -0.32979605E+14&     209\\
   80.000000&   0.18048514E-34&  0.91805682E+17&     237\\
   90.000000&   0.81940126E-39& -0.50516254E+22&     264\\
  100.000000&   0.37200760E-43& -0.29137556E+26&     291 \\\hline   
\end{tabular}  
\caption{Result  from the improved algorithm for $\exp{(-x)}$.}
\end{center}
\end{table} 
%
In this case, we do not get the overflow problem, as can be seen
from the large number of terms. Our results do however
not make much sense for larger values of $x$. Decreasing  the truncation test
will not help! (try it).  This is a much more serious problem.

In order better to understand this problem, let us consider the 
case of $x=20$, which already differs largely from the exact result.
Writing out each term in the summation, we obtain the largest
term in the sum appears at $n=19$, with a value that  equals $-43099804$.
However, for $n=20$ we have almost the same value, but with an interchanged
sign. It means that we
have an error relative to the largest term in the summation of the order
of $43099804\times 10^{-10}\approx 4\times10^{-2}$. 
This is much larger than the exact value of $0.21\times 10^{-8}$.
The large contributions which may appear at a given order in the sum,
lead to strong roundoff errors, which in turn is reflected in the loss
of precision.  
We can rephrase the above in the following way: Since
$\exp{(-20)}$ is a very small number and each term in the series can be rather
large (of the order of $10^{8}$, it is clear that other terms as large
as $10^{8}$, but negative, must cancel the figures in front of the decimal
point and some behind as well. Since a computer can only hold a fixed number of
significant figures, all those in front of the decimal point are not
only useless,
they are crowding out needed figures at the right end of the number.
Unless we are very careful we will find ourselves adding up series that
finally consists entirely of roundoff errors!
An analysis of the 
contribution to the sum from various terms shows that the relative
error made can be huge. This results in an unstable computation, since small
errors made at one stage are magnified in subsequent stages.


To this specific case there is a simple cure. Noting that $\exp{(x)}$ is the 
reciprocal of $\exp{(-x)}$, we may use the series for $\exp{(x)}$ 
in dealing with
the problem of alternating signs, and simply take the inverse. 
One has however to beware of the fact that 
$\exp{(x)}$ may quickly  exceed the range of a double
variable.





\subsection{Fortran codes}




The Fortran  programs are  rather similar in structure to the C++ program. 


In Fortran 
Real numbers are written as 2.0 rather than 2 and declared
as REAL (KIND=8) or REAL (KIND=4) for double or single precision, respectively. 
In general we discorauge the use of
single precision in scientific computing, the achieved precision is in general not good enough. 
Fortran  uses a do construct to have the computer 
execute the same statements more than once. 
Note also that Fortran  does
not allow floating numbers as loop variables.
In the example below we use both a do construct for the loop over $x$ and a\verb? DO WHILE ?
construction for the truncation test, as in the C++ program. One could altrenatively use the
\verb? EXIT ? statement inside a do loop. 
Fortran  has also if statements as in C++.
The IF construct allows the execution of a sequence of statements (a block) to depend on a
condition. The if construct is a compound statement and begins with IF ... THEN and ends
with ENDIF. Examples of more
general IF constructs using ELSE and ELSEIF statements are 
given in other program examples.
Another feature to observe is the CYCLE command, which allows  
a loop variable  to start at a new value.


Subprograms are called from the main program or other subprograms. 
In the C++ codes we declared a function  \verb? TYPE  factorial(int);?.
Subprograms are always called functions in C++. If we declare it with \verb?void? is has the same
meaning as subroutines in Fortran,. Subroutines are used if we have more than one return value.
In the example below we compute the factorials using the 
function\verb? factorial ?. This function receives a dummy argument $n$. 
INTENT(IN) means that the dummy argument 
cannot be changed within the subprogram. 
INTENT(OUT) means that the dummy argument cannot 
be used within the subprogram until it
     is given a value with the intent of passing 
a value back to the calling program. The statement
INTENT(INOUT) means that the dummy argument 
has an initial value which is changed and
passed back to the calling program. We recommend that you use
these options when calling subprograms. This allows better control when transfering variables 
from one function to another. In chapter \ref{chap:differentiate} we discuss call by value and
by reference in C++. Call by value does not allow a called function to change the value
of a given variable in the calling function. This is important in order to avoid unintentional
changes of variables when transfering  data from one function to another. The\verb? INTENT ? 
construct in Fortran  allows such a control. Furthermore, it increases the readability of the program.
\lstset{language=[90]Fortran}
%\begin{lstlisting}[title={programs/chapter2/program4.f90}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/Fortran/program4.f90}}]
! In this module you can define for example global constants
MODULE constants
  ! definition of variables for double precisions and complex variables 
  INTEGER,  PARAMETER :: dp = KIND(1.0D0)
  INTEGER, PARAMETER :: dpc = KIND((1.0D0,1.0D0))
  ! Global Truncation parameter
  REAL(DP), PARAMETER, PUBLIC ::  truncation=1.0E-10
END MODULE constants

! Here you can include specific functions which can be used by
! many subroutines or functions

MODULE functions

CONTAINS
  REAL(DP) FUNCTION factorial(n)
    USE CONSTANTS 
    INTEGER, INTENT(IN) :: n
    INTEGER  :: loop

    factorial = 1.0_dp
    IF ( n > 1 ) THEN
       DO loop = 2, n
          factorial=factorial*loop
       ENDDO
    ENDIF
  END FUNCTION factorial

END MODULE functions
!  Main program starts here
PROGRAM exp_prog
  USE constants
  USE functions
  IMPLICIT NONE  
  REAL (DP) :: x, term, final_sum
  INTEGER :: n, loop_over_x

  !  loop over x-values
  DO loop_over_x=0, 100, 10
     x=loop_over_x
     !  initialize the EXP sum
     final_sum= 0.0_dp; term = 1.0_dp; n = 0 
     DO WHILE ( ABS(term) > truncation)
        term = ((-1.0_dp)**n)*(x**n)/ factorial(n)
        final_sum=final_sum+term
        n=n+1
     ENDDO
     !  write the argument x, the exact value, the computed value and n
     WRITE(*,*) x ,EXP(-x), final_sum, n
  ENDDO

END PROGRAM exp_prog
\end{lstlisting}
The \lstinline?MODULE? declaration in Fortran allows one to place functions
like the one which calculates the factorials. 
Note also the usage of the module {\bf constants} where we define double and complex variables.
If one wishes to switch to another precision, one just needs to change the declaration
in one part of the program only. This hinders possible errors which arise if one has to change
variable declarations in every function and subroutine.   
In addition we have defined a global variable {\bf truncation} which is accessible to all
functions which have the \verb? USE constants? declaration. These declarations have to come
before any variable declarations and \verb?IMPLICIT NONE? statement. 
\lstset{language=[90]Fortran}
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/Fortran/program5.f90}}]
! In this module you can define for example global constants
MODULE constants
  ! definition of variables for double precisions and complex variables 
  INTEGER,  PARAMETER :: dp = KIND(1.0D0)
  INTEGER, PARAMETER :: dpc = KIND((1.0D0,1.0D0))
  ! Global Truncation parameter
  REAL(DP), PARAMETER, PUBLIC ::  truncation=1.0E-10
END MODULE constants

PROGRAM improved_exp
  USE constants
  IMPLICIT NONE  
  REAL (dp) :: x, term, final_sum
  INTEGER  :: n, loop_over_x

  !  loop over x-values, no floats as loop variables
  DO loop_over_x=0, 100, 10
     x=loop_over_x
     !  initialize the EXP sum
     final_sum=1.0 ; term=1.0 ; n = 1
     DO WHILE ( ABS(term) > truncation)
        term = -term*x/FLOAT(n)
        final_sum=final_sum+term
        n=n+1
     ENDDO
     !  write the argument x, the exact value, the computed value and n
     WRITE(*,*) x ,EXP(-x), final_sum, n
  ENDDO

END PROGRAM improved_exp
\end{lstlisting}

\subsection{Further examples}

\subsubsection{Summing $1/n$}

Let us look at another roundoff example which may surprise you more.
Consider the series 
%
\[
    s_1=\sum_{n=1}^{N}\frac{1}{n},
\]
%
which is finite when $N$ is finite. Then consider the alternative way of
writing this sum
%
\[
    s_2=\sum_{n=N}^{1}\frac{1}{n},
\]
%
which when summed analytically should give $s_2=s_1$. Because of roundoff
errors, numerically we will get $s_2 \neq s_1$!
Computing these sums with single precision for $N=1.000.000$
results in
$s_1=14.35736$ while $s_2=14.39265$! Note that these numbers are
machine and compiler dependent. With double precision,
the results agree exactly, however, for larger values of $N$,
differences may appear even for double precision.
If we choose $N=10^8$ and employ double precision, we get 
$s_1=18.9978964829915355$ while $s_2=18.9978964794618506$,
and one notes a difference even with double precision.

This example demonstrates two important topics.
First we notice that the chosen precision is important,
and we will always recommend that you employ double precision
in all calculations with real numbers. 
Secondly, the choice of an appropriate algorithm, as also seen 
for $e^{-x}$, can be of paramount importance for the
outcome.  


\subsubsection{The standard algorithm for the standard deviation}

Yet another example is the calculation of the standard deviation
$\sigma$ when $\sigma$ is small compared to the average value 
$\overline{x}$. 
Below we illustrate how one of the most frequently used 
algorithms can go wrong when single precision is employed.

However, before we proceed, let us define $\sigma$ and 
$\overline{x}$.
Suppose we have a set of $N$ data points, 
represented by the one-dimensional
array $x(i)$, for $i=1, N$. The average value is then 
\[
   \overline{x}=\frac{\sum_{i=1}^{N}x(i)}{N},
\]
while
\[
   \sigma=\sqrt{\frac{\sum_i x(i)^2-\overline{x}\sum_ix(i)}{N-1}}.
\]
Let us now assume that 
\[
   x(i)=i+10^5,
\] 
and that $N=127$, just as a mere example which illustrates 
the kind of problems which can arise when the standard deviation
is small compared with the mean value $\overline{x}$. 

The standard algorithm computes  the two contributions to $\sigma$ separately, that
is we sum $\sum_i x(i)^2$ and subtract thereafter $\overline{x}\sum_ix(i)$.
Since these two numbers can become nearly equal and large, we may end 
up in a situation with potential loss of precision as an outcome.

The second algorithm on the other hand computes first 
$x(i)-\overline{x}$ and then squares it when summing up.  With this recipe we may avoid
having nearly equal numbers which cancel.


Using single precision results in a standard deviation of
$\sigma = 40.05720139 $ for the first and most used algorithm, while the exact
answer is $\sigma = 36.80579758 $, a number which also results from
the above second algorithm. 
With double precision, the two algorithms result in the same answer. 

The reason for such a difference resides in the fact that the first
algorithm includes the 
subtraction of two large numbers which are squared. Since the 
average value for this example is
$\overline{x}=100063.00$, it is easy to see that computing 
$\sum_i x(i)^2-\overline{x}\sum_ix(i)$ can give rise to very large
numbers with possible loss of precision when we perform the 
subtraction. 
To see this, consider the case where $i=64$. Then we have
\[
   x_{64}^2-\overline{x}x_{64}=100352,
\]
while the exact answer is 
\[
   x_{64}^2-\overline{x}x_{64}=100064!
\]
You  can even check this by calculating it by hand. 

The second algorithm computes first the difference between $x(i)$ and
the average value. The difference gets thereafter squared. 
For the second algorithm we have for $i=64$
\[
   x_{64}-\overline{x}=1,
\]
and we have no potential for loss of precision.


The standard text book algorithm is expressed through the following
program, where we have also added the second algorithm
\lstset{language=c++}
%\begin{lstlisting}[title={programs/chapter2/program6.cpp}]
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program6.cpp}}]
// program to calculate the mean and standard deviation of
// a user created data set stored in array x[]
using namespace std;
#include <iostream>
int main()
{
    int      i;
    float    sum, sumsq2, xbar, sigma1, sigma2;
    // array declaration with fixed dimension
    float   x[127];
    //  initialise the data set   
    for ( i=0; i < 127 ; i++){
        x[i] = i + 100000.;
    }
    //  The variable sum is just the sum over all elements  
    //  The variable sumsq2 is the sum over x^2    
    sum=0.; 
    sumsq2=0.;
    //  Now we use the text book algorithm 
    for ( i=0; i < 127; i++){
        sum += x[i];
        sumsq2 += pow((double) x[i],2.);
    }
    //  calculate the average and sigma              
    xbar=sum/127.;
    sigma1=sqrt((sumsq2-sum*xbar)/126.);
    /*
    **  Here comes the second algorithm where we evaluate 
    **  separately first the average and thereafter the   
    **  sum which defines the standard deviation. The average 
    **  has already been evaluated through xbar          
    */
    sumsq2=0.;
    for ( i=0; i < 127; i++){
       sumsq2 += pow( (double) (x[i]-xbar),2.);
    }
    sigma2=sqrt(sumsq2/126.);
    cout << "xbar = `` << xbar << ``sigma1 = `` << sigma1 << ``sigma2 = `` <<  sigma2;
    cout << endl;
    return 0;
}// End: function main() 
\end{lstlisting}
The corresponding Fortran  program is given below.
\lstset{language=[90]Fortran}
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/Fortran/program6.f90}}]
PROGRAM standard_deviation
  IMPLICIT NONE
  REAL (KIND = 4) :: sum, sumsq2, xbar
  REAL (KIND = 4) :: sigma1, sigma2
  REAL (KIND = 4), DIMENSION (127) :: x
  INTEGER :: i

  x=0;
  DO i=1, 127
     x(i) = i + 100000.
  ENDDO
  sum=0.; sumsq2=0.
  !      standard deviation calculated with the first algorithm
  DO i=1, 127
     sum = sum +x(i)

     sumsq2 = sumsq2+x(i)**2
  ENDDO
  !      average
  xbar=sum/127.
  sigma1=SQRT((sumsq2-sum*xbar)/126.)
  !      second algorithm to evaluate the standard deviation
  sumsq2=0.
  DO i=1, 127
     sumsq2=sumsq2+(x(i)-xbar)**2
  ENDDO
  sigma2=SQRT(sumsq2/126.)
  WRITE(*,*) xbar, sigma1, sigma2

END PROGRAM standard_deviation
\end{lstlisting}









\section{Additional Features of C++ and Fortran }

\subsection{Operators in C++}
In the previous program examples we have seen several types of operators.
In the tables below we summarize the most important ones. 
Note that the modulus in C++ is represented by the operator 
\% whereas in Fortran  we employ the intrinsic function \verb?MOD?.
Note also that the increment operator \verb?  ++? and the decrement operator
\verb?  --?  is not available in Fortran .
In C++ these operators have the following meaning
%
\begin{center}
\begin{tabular}{ccccc}
\verb? ++x;? & or &\verb? x++;? & has the same meaning as &
\verb? x = x + 1;? \\
\verb? --x;? & or &\verb? x--;? & has the same meaning as &
\verb? x = x - 1;? \\
\end{tabular}
\end{center}
Table \ref{tab:cexpressions1} lists several relational and arithmetic operators.
\begin{table}
\begin{center}
\begin{tabular}{|cl|cl|} \hline
\multicolumn{2}{|c}{arithmetic operators}
& \multicolumn{2}{|c|}{relation operators}\\ \hline
operator & effect& operator& effect\\ \hline
$-$  & Subtraction       & $>$  & Greater than\\
$+$  & Addition          & $>=$ & Greater or equal\\
$*$  & Multiplication    & $<$  & Less than \\
$/$  & Division          & $<=$ & Less or equal\\
$\%$ or MOD & Modulus division & $==$ & Equal\\
$--$ & Decrement         & $!=$ & Not equal\\
$++$ & Increment         &      & \\ \hline 
\end{tabular}
\caption{Relational and arithmetic operators. The relation operators act between 
two operands. Note that the increment 
and decrement operators $++$ and
$--$ are not available in Fortran . \label{tab:cexpressions1}}
\end{center}
\end{table}
%
Logical operators in C++ and Fortran  are listed in \ref{tab:cexpressions2}.
\begin{table}
\begin{center}
\begin{tabular}{|clc|} \hline
\multicolumn{3}{|c|}{Logical operators}\\ \hline
C++  & Effect & Fortran \\ \hline
0 & False value & .FALSE. \\
1 & True value & .TRUE. \\
!x & Logical negation & .NOT.x\\
x\&\& y & Logical AND   &        x.AND.y\\
x||y   & Logical inclusive OR    & x.OR.y \\
\hline
\end{tabular}
\caption{List of logical operators in C++ and Fortran .\label{tab:cexpressions2}}
\end{center}
\end{table}
%
while Table \ref{tab:cexpressions3} shows bitwise operations.
\begin{table}
\begin{center}
\begin{tabular}{|clc|} \hline
\multicolumn{3}{|c|}{Bitwise operations}\\ \hline
C++ & Effect & Fortran   \\ \hline
\verb?~i?   &Bitwise complement       &NOT(j)  \\
\verb?i&j?     &Bitwise and       &IAND(i,j)   \\
 \verb?i^j?    & Bitwise exclusive or      &IEOR(i,j)   \\
\verb?i|j? & Bitwise inclusive or & IOR(i,j) \\
\verb?i<<j? & Bitwise shift left & ISHFT(i,j) \\
\verb?i>>n? & Bitwise shift right & ISHFT(i,-j) \\
\hline
\end{tabular}
\caption{List of bitwise operations. \label{tab:cexpressions3}}
\end{center}
\end{table}
 
C++ offers also interesting possibilities for combined operators. 
These are collected in Table \ref{tab:cexpressions4}.
%
\begin{table}
\begin{center}
\begin{tabular}{|cc|cc|} \hline
Expression & meaning & expression & meaning\\ \hline
\tt a += b;  & \tt a = a + b;  & \tt a  -= b;  & \tt a = a  -
b;\\
\tt a *= b;  & \tt a = a * b;  & \tt a  /= b;  & \tt a = a  /
b;\\
\tt a \%= b;  & \tt a = a \% b;  & \tt a <<= b;  & \tt a = a 
<< b;\\
\tt a >>= b; & \tt a = a >> b; & \tt a \&= b;  & \tt a = a \&
b;\\
\tt a |= b;  & \tt a = a | b;  & \tt a $\scriptstyle \wedge$=
b;  & 
\tt a = a $\scriptstyle \wedge$ b;\\
\hline
\end{tabular}\\[1ex]
\caption{C++ specific expressions. \label{tab:cexpressions4}}
\end{center}
\end{table}

Finally, we show some special operators pertinent to C++ only.
The first one is
the {\tt ?}\ operator. 
Its action can be described through the following example
\begin{center}
{\tt A = expression1\ ? \ expression2\ : \ expression3;}
\end{center}
%
Here {\tt expression1} is computed first. If this is 
{\em"true"} 
($\neq 0$), then {\tt expression2} is computed and assigned  A. If
{\tt expression1}
is {\em"false"}, then {\tt expression3} is computed and assigned A.  


\subsection{Pointers and arrays in C++.}
In addition to constants and variables C++ contain important 
types such as pointers and arrays (vectors and matrices). These are widely
used in most C++ program. C++ allows also for pointer algebra, a feature not included
in Fortran .
Pointers and arrays are important elements in C++. 
To shed light on these types, consider the following setup
%
\begin{center}
\begin{tabular}{ll}
\begin{minipage}[t]{0.2\textwidth}
\tt int name
\end{minipage}
&
\begin{minipage}[t]{0.7\textwidth}
defines an integer variable called {\tt name}. It is given an address in memory
where we can store an integer number.
\end{minipage} \vspace*{3mm}\\
\begin{minipage}[t]{0.2\textwidth}
\tt {\&}name
\end{minipage}
&
\begin{minipage}[t]{0.7\textwidth}
is the address of a specific place in memory where the 
integer {\tt name} is stored.
Placing the operator
{\&} in front of a variable yields its address in memory.
\end{minipage} \vspace*{3mm}\\
\begin{minipage}[t]{0.2\textwidth}
\tt int *pointer
\end{minipage}
&
\begin{minipage}[t]{0.7\textwidth}
defines an integer pointer and reserves a location in memory
for this specific variable
The content of this location is viewed as the address of another place
in memory where we have stored an integer.
\end{minipage}\\
\end{tabular}
\end{center}
%
Note that in C++ it is common to write \verb?int* pointer? while in C one usually
writes \verb?int *pointer?.
Here are some examples of legal C++ expressions.
%
\begin{center}
\begin{tabular}{lll}
{\tt name = 0x56;}
&
/* name gets the hexadecimal value hex 56. &*/ \\
{\tt pointer = {\&}name;}
&
/* pointer points to name. &*/\\
{\tt printf("Address of name = \%p",pointer);}
&
/* writes out the address of name. &*/\\
{\tt printf("Value of name= \%d",*pointer);\hspace*{1mm}}
&
/* writes out the value of name. &*/\\
\end{tabular}
\end{center}
Here's a program which illustrates some of these topics.
\lstset{language=c++}
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program7.cpp}}]
 1   using namespace std;
 2   main()  
 3     {  
 4       int var;                    
 5       int *pointer;  
 6  
 7       pointer = &var;  
 8       var  = 421;  
 9       printf("Address of the integer variable var : %p\n",&var);
10       printf("Value of var : %d\n", var);
11       printf("Value of the integer pointer variable: %p\n",pointer);
12       printf("Value which pointer is pointing at :  %d\n",*pointer);
13       printf("Address of the pointer variable : %p\n",&pointer);
14     }
\end{lstlisting}

{\small
\begin{center}
%
\begin{tabular}{|ll|}\hline
\hfill Line \hfill
&\hspace*{\fill} Comments \hspace*{\fill}\\ \hline
&  \\[-2mm]
4 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Defines an integer variable var.
\end{minipage}\\
5 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Define an integer pointer  -- reserves space in memory.
\end{minipage}\\
7 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
The content of the adddress of  pointer is the  address of var.
\end{minipage}\\
8 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
The value of  var is 421.
\end{minipage}\\
9 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Writes the address of  var in hexadecimal notation for pointers \%p.
\end{minipage}\\
10 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Writes the value of  var in decimal notation\%d.
\end{minipage}\\[1ex]
\hline
\end{tabular}
\end{center}
} % end small
%
The ouput of this program, compiled with g++, reads
\begin{svgraybox}
\begin{verbatim}
Address of the integer variable var : 0xbfffeb74
Value of var: 421
Value of integer pointer variable : 0xbfffeb74
The value which pointer is pointing at :  421
Address of the pointer variable : 0xbfffeb70
\end{verbatim}
\end{svgraybox}
In the next example we consider the link between arrays and pointers.
\begin{center}
\begin{tabular}{ll}
\begin{minipage}[t]{0.2\textwidth}
\tt int matr[2]
\vspace*{2mm}
\end{minipage}
&
\begin{minipage}[t]{0.7\textwidth}
defines a matrix with two integer members
-- {\tt matr[0]} og {\tt matr[1]}.
\end{minipage}\\[1ex]
\begin{minipage}[t]{0.2\textwidth}
\tt matr
\end{minipage}
&
\begin{minipage}[t]{0.7\textwidth}
is a pointer to {\tt matr[0]}.
\end{minipage}\\[1ex]
%
\begin{minipage}[t]{0.2\textwidth}
\tt (matr + 1)
\end{minipage}
&
\begin{minipage}[t]{0.7\textwidth}
is a pointer to {\tt matr[1]}.
\end{minipage}\\
\end{tabular}
\end{center}
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter02/cpp/program8.cpp}}]
 1   using namespace std;
 2   #included <iostream>
 3   int main()  
 4     {   
 5        int matr[2];  
 6        int *pointer;  
 7        pointer = &matr[0];  
 8        matr[0] = 321;  
 9        matr[1] = 322;  
10        printf("\nAddress of the matrix element matr[1]: %p",&matr[0]);
11        printf("\nValue of the matrix element  matr[1]; %d",matr[0]);
12        printf("\nAddress of the matrix element matr[2]: %p",&matr[1]);
13        printf("\nValue of the matrix element  matr[2]: %d\n", matr[1]);
14        printf("\nValue of the pointer : %p",pointer);
15        printf("\nValue which pointer points at  : %d",*pointer);
16        printf("\nValue which  (pointer+1) points at: %d\n",*(pointer+1));
17        printf("\nAddress of the pointer variable: %p\n",&pointer);
18     }
\end{lstlisting}
You should especially pay attention to the following
%
{\small
\begin{center}
%
\begin{tabular}{|ll|}\hline
\hfill Line \hfill
&\hspace*{\fill}  \hspace*{\fill}\\ \hline
&  \\[-2mm]
5 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Declaration of an integer array matr with two elements
\end{minipage}\\
6 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Declaration of an integer pointer
\end{minipage}\\
7 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
The pointer is initialized to point at the first element of the 
array matr.
\end{minipage}\\
8--9 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Values are assigned to the array matr.
\end{minipage}\\[1ex]  
\hline  
\end{tabular}  
\end{center}  
} % end small  
The ouput of this example, compiled again with g++, is
\begin{svgraybox}
\begin{verbatim}
Address of the matrix element matr[1]: 0xbfffef70
Value of the  matrix element  matr[1]; 321
Address of the matrix element matr[2]: 0xbfffef74
Value of the matrix element  matr[2]: 322
Value of the pointer: 0xbfffef70
The value pointer points at: 321
The value that (pointer+1) points at:  322
Address of the pointer variable : 0xbfffef6c
\end{verbatim}
\end{svgraybox}


\subsection{Macros in C++}

In C we can define macros, typically global constants or functions through
the \verb?define? statements shown in the simple C-example below for  
\begin{lstlisting}
1.   #define ONE      1
2.   #define TWO      ONE + ONE
3.   #define THREE    ONE + TWO
4.
5.   main()
6.      {
7.         printf("ONE=%d, TWO=%d, THREE=%d",ONE,TWO,THREE);
8.      } 
\end{lstlisting}
In C++ the usage of macros is discouraged and you should rather use 
the declaration for constant variables. You would then replace a statement like
\verb? #define ONE  1? with \verb? const int ONE = 1;?. There is typically much less use of
macros in C++ than in C. 
C++ allows also the definition of our own types based on other existing data types. 
We can do this using the keyword typedef, whose format is:
\verb? typedef existing_type new_type_name ;?,
where existing\_type is a C++ fundamental or compound type and new\_type\_name is the name for the new type we are defining. For example:
\begin{lstlisting}
typedef char new_name;
typedef unsigned int word ;
typedef char * test;
typedef char field [50]; 
\end{lstlisting}
In this case we have defined four data types: new\_name, word, test and field as char, 
unsigned int, char* and char[50] respectively, that we could perfectly use in declarations later as any other valid type
\begin{lstlisting}
new_name mychar, anotherchar, *ptc1;
word myword;
test ptc2;
field name; 
\end{lstlisting}
The use of typedef does not create different types. 
It only creates synonyms of existing types. 
That means that the type of \verb?myword? can be considered to be either word or unsigned int, 
since both are in fact the same type.
Using
typedef allows to define an alias for a type that is frequently used within a program. 
It is also useful to define types when it is possible that we will need to 
change the type in later versions of our program, 
or if a type you want to use has a name that is too long or confusing.

In C we could define macros for functions as well, as seen below.
\begin{lstlisting}
1.   #define   MIN(a,b)     ( ((a) < (b)) ?  (a) : (b) )
2.   #define   MAX(a,b)     ( ((a) > (b)) ?  (a) : (b) )
3.   #define   ABS(a)       ( ((a) < 0)   ? -(a) : (a) )
4.   #define   EVEN(a)      ( (a) %2 == 0 ?   1  :  0  )
5.   #define   TOASCII(a)   ( (a)  & 0x7f )
\end{lstlisting}
In C++ we would replace such function definition by employing so-called \verb?inline?
functions. The above functions could then read
\begin{lstlisting}
inline double MIN(double a,double b) (return (((a)<(b)) ? (a):(b));)
inline double MAX(double a,double b)(return (((a)>(b)) ? (a):(b));)
inline double ABS(double a) (return (((a)<0) ? -(a):(a));)
\end{lstlisting}
where we have defined the transferred variables to be of type \verb?double?. The functions
also return a \verb?double? type. These functions could easily be generalized through the use
of classes and templates, see chapter \ref{chap:linalgebra}, to return whather types of 
real, complex or integer variables.

Inline functions are very useful, especially if the overhead for calling a function  
implies a significant fraction of the total function call cost. When such function call overhead
is significant, a function definition can be preceded by the keyword \verb?inline?.
When this function is called, we expect the compiler to generate inline code without function
call overhead. However, although inline functions eliminate function call overhead, they can
introduce other overheads. When a function is inlined, its code is duplicated for each call.
Excessive use of \verb?inline? may thus generate large programs. Large programs can cause
excessive paging in virtual memory systems.
Too many inline functions can also lengthen compile and link times, on the other hand not inlining 
small functions like the above that do small computations, can make programs bigger and slower.
However, most modern compilers know better than programmer which functions to inline or not.
When doing this, you should also test various compiler options. With the compiler option
$-O3$ inlining is done automatically by basically all modern compilers. 

A good strategy, recommended in many C++ textbooks, is to write a code without inline functions first.
As we also suggested in the introductory chapter, 
you should first write a as simple and clear 
as possible program, without
a strong emphasis on computational speed. 
Thereafter, when profiling the program one can spot small functions which are called many times.
These functions can then be candidates for inlining. 
If the overall time comsumption is reduced due to inlining
specific functions, we can proceed to other sections of the program which could be speeded up.

Another problem with inlined functions is that on some systems debugging an inline 
function is difficult because the function does not exist at runtime.



\subsection{Structures  in  C++ and TYPE in Fortran }

A very important part  of a program is the way we organize
our data and the flow of data when running the code. 
This is  often a neglected aspect especially during the development of an algorithm.
A clear understanding of how data are represented makes the program more 
readable and easier to maintain and extend upon by other users. 
Till now we have studied elementary variable declarations through keywords
like \verb?int? or \verb?INTEGER?, 
\verb?double? or \verb?REAL(KIND(8)? and \verb?char? or its
Fortran  equivalent \verb?CHARACTER?. 
These declarations could also be extended to general multi-dimensional arrays.

However, 
C++ and Fortran  offer other ways as well by which we can organize
our data in  a more transparent and reusable way. One of these 
options is through the \verb?struct? declaration of C++, 
or the correspondingly similar \verb?TYPE? in Fortran. The latter data type 
will also be discussed in chapter \ref{chap:linalgebra}.

The following example illustrates how we could make a general variable
which can be reused in defining other variables as well.

Suppose you would like to make a general program which treats quantum
mechanical problems from both atomic physics and nuclear physics. 
In atomic and nuclear physics the single-particle degrees are represented
by quantum numbers such orbital angular momentum, total angular momentum,
spin and energy. An independent particle model is often assumed as the starting
point for building up more complicated many-body correlations in systems
with many interacting particles. In atomic physics the effective 
degrees of freedom are often reduced to electrons interacting with each other, while in nuclear physics the system is described by neutrons and protons. 
The structure 
\verb? single_particle_descript? contains a list over different quantum 
numbers through various pointers which are initialized by a calling function.

\begin{lstlisting}
struct single_particle_descript{
            int total_states;
            int* n;
            int* lorb;
            int* m_l;
            int* jang;
            int* spin;
            double* energy;
            char* orbit_status
     };
\end{lstlisting}
To describe an atom like Neon we would need three 
single-particle orbits to describe the ground state wave function if we use
a single-particle picture, i.e., the $1s$, $2s$ and $2p$ 
single-particle orbits. These orbits have a degeneray of $2(2l+1)$,
where the first number stems from the possible spin projections and the second
from the possible projections of the orbital momentum.  Note that we reserve the naming orbit  for the generic labelling $1s$, $2s$ and $2p$ while we use the naming states when we include all possible quantum numbers. 
In total there are 10 possible single-particle states when we account for
spin and orbital momentum projections. In this case we would thus need
to allocate memory for arrays containing 10 elements.

The above structure is written in a generic way and it can be used to define
other variables as well. For electrons we could write 
\verb?struct single_particle_descript electrons;?
and is a new variable with the name \verb?electrons? containing all the elements
of this structure. 

The following program segment illustrates how we access these elements
To access these elements we could for example read from a given device the various
quantum numbers:
\begin{lstlisting}
    for ( int i = 0; i < electrons.total_states; i++){
        cout << `` Read in the quantum numbers for electron i: `` << i << endl;
        cin >> electrons.n[i];
        cin > electrons.lorb[i];
        cin >> electrons.m_l[i];
        cin >> electrons.jang[i];
        cin >> electrons.spin[i];
    } 
\end{lstlisting}
The structure {\tt single\_particle\_descript} can also be used for defining 
quantum numbers of other particles as well, such as neutrons and protons throughthe new variables
\verb? struct single_particle_descript protons? and 
\verb? struct single_particle_descript neutrons?. 


The corresponding declaration in Fortran is given by the \verb$TYPE$ construct, seen in the
following example.
\lstset{language=[90]Fortran}
\begin{lstlisting}
 TYPE, PUBLIC :: single_particle_descript
     INTEGER :: total_states
     INTEGER, DIMENSION(:), POINTER :: n, lorb, jang, spin, m_l
     CHARACTER (LEN=10), DIMENSION(:), POINTER :: orbit_status
     REAL(8), DIMENSION(:), POINTER :: energy
  END TYPE single_particle_descript
\end{lstlisting}
This structure can again be used to define variables like {\tt electrons},
{\tt protons} and {\tt neutrons}  through the statement 
\verb?TYPE (single_particle_descript) :: electrons, protons, neutrons?.
More detailed examples on the use of these variable declarations, classes and templates will be given 
in subsequent chapters.


\section{Exercises}

%\subsection*{prob 2.1: Converting from decimal to binary representation}
\begin{prob}
Set up an algorithm
which converts a floating number given in the decimal representation 
to the binary representation. You may or may not use a scientific representation.
Write thereafter a program which implements this algorithm. 
\end{prob}


%\subsection*{prob 2.2: Summing series}
\begin{prob}
Make a program which sums
\begin{enumerate}
\item
\[
   s_{\mathrm{up}}=\sum_{n=1}^{N}\frac{1}{n},
\]
and
\[
   s_{\mathrm{down}}=\sum_{n=N}^{n=1}\frac{1}{n}.
\]
The program should read $N$ from screen and write the final output to screen.
\item
Compare  $s_{\mathrm{up}}$ og $s_{\mathrm{down}}$ for different $N$ 
using both single and double precision for $N$ up to $N=10^{10}$.
Which of the above formula is the most realiable one? 
Try to give an explanation of possible differences. 
One possibility for guiding the eye is 
for example to make  
a log-log plot of the  relative difference as a function of  $N$ in steps of $10^n$
with $n=1,2,\dots,10$. This means you need to compute 
$log_{10}(|(s_{\mathrm{up}}(N)-s_{\mathrm{down}}(N))/s_{\mathrm{down}}(N)|)$
as function of  $log_{10}(N)$. 
\end{enumerate}
\end{prob}


%\subsection*{prob 2.3: Finding alternative expressions}
\begin{prob}
Write a program which computes 
\[
   f(x) = x -\sin{x},
\]
for a wide range of values of $x$.  Make a careful analysis of this function for values
of $x$ near zero. For $x \approx 0$ you may consider to write out the series expansions of 
$\sin{x}$
\[
   \sin{x} = x -\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\dots
\]
Use the loss of precision theorem of Eq.~(\ref{eq:lossofprecision})  to show that the loss of bits 
can be limited to at most one bit by restricting $x$ so that
\[
  1-\frac{\sin{x}}{x}  \ge \frac{1}{2}.
\]
One finds then that $x$ must at least be 1.9, implying that for $|x| < 1.9$ we need to carefully
consider the series expansion. For $|x|\ge 1.9$ we can use directly the expression
$x-\sin{x}$.  

For $|x| < 1.9$ you should device a recurrence relation for the terms in the series
expansion in order to avoid having to compute very large factorials.
\end{prob}


\begin{prob}
%\subsection*{prob 2.4: Computing $e^{-x}$}
Assume that you do not have access to the intrinsic function for $\exp{x}$. Write your own
algorithm for $\exp{(-x)}$  for all possible values of $x$, with special care on how to 
avoid the loss of precision problems
discussed in the text.  Write thereafter a program which implements this algorithm.
\end{prob}


%\subsection*{prob 2.5: Computing the quadratic equation}
\begin{prob}
The classical quadratic equation $ax^2+bx+c=$ with solution
\[
      x = \left(-b\pm \sqrt{b^2-4ac}\right)/2a,
\]
needs particular attention when $4ac$ is small relative to $b^2$. Find an algorithm which 
yields stable results for all possible values of $a$, $b$ and $c$. Write thereafter a program and 
test the results of your computations.
\end{prob}


\begin{prob}
%\subsection*{prob 2.6: Fortran, C++ and Python functions for machine rounding}
Write a Fortran program which reads a real number $x$ and computes the precision in bits (using the function
\lstinline{DIGIT(x)})for single and double precision, the smallest positive number
(using \lstinline{TINY(x)}), the largets positive number (using the function \lstinline{HUGE(x)})
and the number of leading digits (using the function \lstinline{PRECISION(x)}).  
Try thereafter to find similar functionalities in C++ and Python.
\end{prob}


\begin{prob}
%\subsection*{prob 2.7: Nearest machine number}
Write an algorithm and program which reads in a real number $x$ and finds the two nearest machine
numbers $x_{-}$ and $x_{+}$, the corresponding relative errors and absolute errors.  
\end{prob}


\begin{prob}
%\subsection*{prob 2.8: Recurrence relations}
Recurrence relations are
extremely useful in representing functions, and form expedient ways of
representing important classes of functions used in the Sciences. We will
see two such examples in the discussion below.
%
One example of recurrence relations appears in studies
of Fourier series, which enter studies of
wave mechanics, be it either in classical systems or quantum
mechanical ones. We may need to calculate in an efficient 
way sums like
%
\begin{equation}
   F(x)=\sum_{n=0}^{N}a_n cos(nx),
\label{four-1}
\end{equation}
%
where the coefficients $a_n$ are known numbers and $x$ is the argument of
the function $F()$. If we want to solve this problem
right on, we could write a simple repetitive loop that 
multiplies each of the cosines with its respective 
coefficient $a_n$ like
\begin{lstlisting}
    for ( n=0; n < N; n++){
       f +=  an*cos(n*x)
    }
\end{lstlisting}

Even though this seems rather straightforward, it may
actually yield a waste of computer time if $N$ is large.
The interesting point here is that through the three-term
recurrence relation
%
\begin{equation}
cos(n-1)x-2cos(x)cos(nx)+cos(n+1)x=0,
\label{four-2}
\end{equation}
%
we can express the entire finite Fourier series in terms
of $cos(x)$ and two constants. The essential device is
to define a new sequence of coefficients 
$b_n$ recursively by
%
\begin{equation}
b_n=(2cos(x))b_{n-1}-b_{n+2}+a_n \hspace{1cm} n=0,\dots N-1, N,
\label{four-3}
\end{equation}
%
defining $b_{N+1}=b_{N+2}+..\dots=0$ for all $n>N$, the upper limit.
We can then determine all the $b_n$ coefficients from $a_n$ and one evaluation
of $2cos(x)$. If we replace $a_n$ with $b_n$ in the sum for $F(x)$ 
in Eq.~(\ref{four-1}) we obtain 
%
\begin{eqnarray}
    F(x)=&b_N\left[cos(Nx)-2cos((N-1)x)cos(x)+cos((N-2)x)\right]  + \nonumber\\
       &b_{N-1}\left[cos((N-1)x)-2cos((N-2)x)cos(x)+cos((N-3)x)\right]  +\dots \nonumber\\
   &b_2\left[cos(2x)-2cos^2(x)+1\right]  + b_1\left[cos(x)-2cos(x)\right]+b_0.
\end{eqnarray}  
%
Using Eq.~(\ref{four-2}) we obtain the final result
\begin{equation}
    F(x)=b_0-b_1cos(x),
 \label{four-4}
\end{equation}
%
and $b_0$ and $b_1$ are determined from Eq.~(\ref{four-1}). 
The latter relation is after Chensaw. 
This method of evaluating finite series of orthogonal functions that are connected by a linear recurrence is a technique generally available for all standard
special functions in mathematical physics, like Legendre polynomials,
Bessel functions etc. They all involve two or three terms in the recurrence
relations. The general relation can then be written as 
\[
   F_{n+1}(x)=\alpha_n(x)F_n(x)+\beta_n(x)F_{n-1}(x).
\]
Evaluate the function $F(x)=\sum_{n=0}^{N}a_n cos(nx)$
in two ways: first by computing the series of Eq.~(ref{four-1})
and then using the equation given in Eq.~(\ref{four-3}).
Assume that $a_n=(n+2)/(n+1)$, set e.g., $N=1000$ and try with different
$x$-values as input.
\end{prob}


\begin{prob}
%\subsection*{prob 2.9: Continued fractions}

 Often, especially when one encounters singular behaviors, one may
 need to rewrite the function to be evaluated in terms of a taylor
 expansion. Another possibility is to used so-called continued fractions,
 which may be viewed as generalizations of a Taylor expansion.
 When dealing with continued fractions, one possible approach is that
 of successive substitutions. Let us illustrate this by a simple example,
 namely the solution of a second order equation
%
 \be \label{eq:exercise210}
    x^2-4x-1=0,
 \ee
%
 which we rewrite as
%
 \[
     x=\frac{1}{4+x},
 \]
%
 which in turn could be represented through an iterative substitution
 process 
%
 \[
     x_{n+1}=\frac{1}{4+x_{n}},
 \]
%
 with $x_0=0$. This means that we have
%
 \[
     x_{1}=\frac{1}{4},
 \]
%
 \[
     x_{2}=\frac{1}{4+\frac{1}{4}},
 \]
%
 \[
     x_{3}=\frac{1}{4+\frac{1}{4+\frac{1}{4}}},
 \]
%
 and so forth.
 This is often rewritten in a compact way as 
 \[
     x_{n}=x_0+\frac{a1}{x_1+\frac{a_2}{x_2+\frac{a_3}
                {x_3+\frac{a_4}{x_4+\dots}} }},
 \]
%
 or as 
%
 \[
     x_{n}=x_0+\frac{a1}{x_1+}\frac{a2}{x_2+}\frac{a3}{x_3+}\dots
 \]

Write a program which implements this continued fraction algorithm and solve 
iteratively Eq.~(\ref{eq:exercise210}).   The exact solution is  $x=0.23607$ 
 while already after three iterations you should obtain $x_3=0.236111$.
\end{prob}


\begin{prob}
%\subsection*{Project 2.1: Special functions, spherical harmonics and associated Legendre polynomials}
Many physics problems have spherical harmonics as solutions, such as the angular part of
the Schr\"odinger equation for the hydrogen atom or the angular part of the three-dimensional 
wave equation or Poisson's equation. 

The spherical harmonics for a given orbital momentum $L$, its projection $M$ for 
$-L \le M \le L$ and angles $\theta \in [0,\pi]$ and
$\phi \in [0, 2\pi]$ are given by 
\[
  Y_L^M(\theta, \phi)=\sqrt{\frac{(2L+1)(L-M)!}{4\pi (L+M)!}}
                      P_L^M(cos(\theta))\exp{(iM\phi)},
\]
The functions $P_L^M(cos(\theta)$ are the so-called associated Legendre functions. 
They are normally determined
via the usage of recurrence relations. Recurrence relations are unfortunately often unstable,
but the following relation is stable  (with $x=cos(\theta)$)
\[
(L-M)P_L^M(x) = x(2L-1)P_{L-1}^M(x)-(L+M-1)P_{L-2}^M(x),
\]
and with the analytic (on closed form) expressions  
\[
P_M^M(x) = (-1)^M(2M-1)!!(1-x^2)^{M/2},
\]
and
\[
P_{M+1}^M(x) = x(2M+1)P_{M}^M(x),
\]
we have the starting values and the equations necessary for generating the associated Legendre
functions for a general value of $L$. 

\begin{enumerate}
\item  Make first a function which computes the associated Legendre functions
for different values of $L$ and $M$. Compare with the closed-form results listed in
chapter \ref{chap:integrate}. 
\item 
      Make thereafter a  program which calculates the real part of the 
      spherical harmonics 

\item Make plots for various $L=M$ as functions of $\theta$ (set $\phi=0$)
   and study the behavior as $L$ is increased.  Try to explain why 
   the functions become more and more narrow as $L$ increases.  In order to make these plots
you can use for example gnuplot, as discussed in appendix \ref{sec:gnuplot}.
\item  Study also the behavior of the spherical harmonics when $\theta$
   is close to 0 and when it approaches 180 degrees. Try to extract
   a simple explanation for what you see.
\end{enumerate}
\end{prob}


\begin{prob}
%\subsection*{Project 2.2: Special functions, Laguerre and Hermite polynomials}
Other well-known polynomials are the Laguerre and the Hermite polynomials, both being solutions 
to famous differential equations.
The Laguerre polynomials arise from the solution of the differential
equation
\[
\left(\frac{d^2 }{dx^2}-\frac{d }{dx}+\frac{\lambda}{x}-\frac{l(l+1)}{x^2}\right){\cal L}(x)=0,
\]
where $l$ is an integer $l\ge 0$ and $\lambda$ a constant. This equation
arises for example from the solution of the radial Schr\"odinger equation with 
a centrally symmetric potential such as the Coulomb potential.
The first polynomials are
\[
   {\cal L}_0(x)=1,
\]
\[
    {\cal L}_1(x)=1-x,
\]
\[
    {\cal L}_2(x)=2-4x+x^2,
\]
\[
    {\cal L}_3(x)=6-18x+9x^2-x^3,
\]
and
\[
    {\cal L}_4(x)=x^4-16x^3+72x^2-96x+24.
\]
They fulfil the orthogonality relation
\[
  \int_{-\infty}^{\infty}e^{-x}{\cal L}_n(x)^2dx=1,
\]
and the recursion relation
\[
  (n+1){\cal L}_{n+1}(x)=(2n+1-x){\cal L}_{n}(x)-n{\cal L}_{n-1}(x).
\]
Similalry, the Hermite polynomials are solutions of the differential equation
\[
   \frac{d^2H(x)}{dx^2}-2x\frac{dH(x)}{dx}+
       (\lambda-1)H(x)=0,
\]
which arises for example by solving Schr\"odinger's equation for a particle confined to move 
in a harmonic oscillator potential.
The first few polynomials are
\[
   H_0(x)=1,
\]
\[
    H_1(x)=2x,
\]
\[
    H_2(x)=4x^2-2,
\]
\[
    H_3(x)=8x^3-12,
\]
and
\[
    H_4(x)=16x^4-48x^2+12.
\]
They fulfil the orthogonality relation
\[
  \int_{-\infty}^{\infty}e^{-x^2}H_n(x)^2dx=2^nn!\sqrt{\pi},
\]
and the recursion relation
\[
  H_{n+1}(x)=2xH_{n}(x)-2nH_{n-1}(x).
\]
Write a program which computes the above Laguerre and Hermite polynomials 
for different values of $n$ using the pertinent recursion relations. 
Check your results agains some selected closed-form expressions.
\end{prob}














Furthermore, we will use this section to introduce three
important C++-programming features, namely reading and writing to
a file, call by reference and call by value, and dynamic memory allocation.
We are also going to split the tasks performed
by the program into subtasks. We define one function
which reads in the input data, one which calculates the second derivative
and a final function
which writes the results to file.


Let us look at a simple case first, the use of 
\verb?printf? and \verb?scanf?. If we wish to print
a  variable defined as  
\verb?double speed_of_sound;?
we could  for example write 
\begin{lstlisting}
double speed_of_sound;
.....
printf(``speed_of_sound = %lf\n'', speed_of_sound);
\end{lstlisting}

In this case we say that we transfer the value of this specific variable
to the function \verb?printf?. The function \verb?printf? 
{\em can however not change the value of this variable} 
(there is no need to do so in this case). 
Such a call
of a specific  function is called {\em call by value}. 
The crucial aspect to keep in mind is that the value of this
specific variable does not change in the called function.

When do we use call by value? And why care at all? 
We do actually care, because if a called function has the possibility
to change the value of a variable when this is not desired,
calling another function with this variable may lead to totally wrong
results. In the worst cases you may even not be able to spot where the
program goes wrong. 

We do however use call by value when a called function
simply receives the value of the given variable without changing it.

If we however wish to update the value of say an array 
in a called function, we refer to this call as {\bf call by reference}.
What is transferred then is the address of the first element of the array,
and the called function has now access to where that specific
variable 'lives' and can thereafter change its value. 

The function \verb?scanf? is then an example of a function which receives
the address of a variable and is allowed to modify it. Afterall, when calling
\verb?scanf? we are expecting a new value for a variable. 
A typical call could be
\verb?scanf(``%lf\n'', &speed_of_sound);?.

Consider now the following program
\lstset{language=c++}
\begin{lstlisting}
1  using namespace std;
2  # include  <iostream> 
3  // begin main function
4  int main(int argc, char argv[])
   {
5     int a;                                     
6     int *b;                                    
7     a = 10;                                     
8     b = new int[10];
9     for( int i = 0; i < 10; i++){
10       b[i] = i;
11    }
12    func(a,b);
13    return 0;
14 }   // end of main function   
15 //   definition of the function func
16 void func(int x, int *y)
17 {
18    x += 7; 
19    *y += 10;
20    y[6] += 10;
21    return;
22 } // end function func
\end{lstlisting}
There are several features to be noted.
\begin{itemize}
%
\item Lines 5 and 6: Declaration of two variables a and b. The
compiler reserves two locations in memory. The size of the location
depends on the type of variable. Two properties are important for
these locations -- the address in memory and the content in the
%
\item Line 7: The value of a is now 10.
%
\item Line 8: Memory to store 10 integers is reserved. The
address to the first location is stored in b. The address of element
number 6 is given by the expression (b + 6). 
%
\item Line 10: All 10 elements of b are given values: b[0] = 0, b[1] =
1, ....., b[9] = 9;
% 
\item Line 12: The main() function calls the function func() and the
program counter transfers to the first statement in func().
With respect to data the following happens. The content of a 
(= 10) and the content of b (a memory address) are copied to a stack
(new memory location) associated with the function func()
%
\item Line 16: The variable x and y are local variables in
func(). They have the values -- x = 10, y = address of the first
element in b in the main() program.
%
\item Line 18: The local variable x stored in the stack memory is
changed to 17. Nothing happens with the value a in main().
% 
\item Line 19: The value of y is an address and the symbol *y stands for 
the position in memory which has this address. The value in this
location is now increased by 10. This means that the value of b[0] in
the main program is equal to 10. Thus func() has modified a value in main().
%
\item Line 20: This statement has the same effect as line 9 except
that it modifies element b[6] in main() by adding a value of 10 to
what was there originally, namely 6.
% 
\item Line 21: The program counter returns to main(), the next
expression after {\sl func(a,b);}. All data on the stack associated
with func() are destroyed.
%
\item The value of a is transferred to func() and stored
in a new memory location called x. Any modification of x in func()
does not affect in any way the value of a in main(). This is called {\bf
transfer of data by value}. On the other hand the next argument in
func() is an address which is transferred to func(). This address can
be used to modify the corresponding value in main(). In the programming  language C
it is expressed as a modification of the value 
which y points to, namely the first element of b.
This is called {\bf transfer of data by reference} and is a method to
transfer data back to the calling function, in this case  main().
% 
\end{itemize}
C++ allows however the programmer to use solely call by reference
(note that call by reference is implemented as pointers).
To see the difference between C and C++, consider the following simple
examples. In C we would write
\lstset{language=c++}
\begin{lstlisting}
   int n; n =8;
   func(&n); /* &n is a pointer to n */
   ....
   void func(int *i)
   {
     *i = 10; /* n is changed to 10 */
     ....
   }
\end{lstlisting}
whereas in C++ we would write

\begin{lstlisting}
   int n; n =8;
   func(n); // just transfer n itself
   ....
   void func(int& i)
   {
     i = 10; // n is changed to 10
     ....
   }
\end{lstlisting}
Note well that the way we have defined the input to the function 
\verb?func(int& i)? or \verb?func(int *i)? decides how we transfer
variables to a specific function.
The reason why we emphasize the difference between call by value and call 
by reference is that it allows the programmer to avoid pitfalls
like unwanted changes of variables. However, many people feel that this
reduces the readability of the code.
It is more or less common in C++ to use call by reference, since it gives a 
much cleaner code. Recall also that behind the curtain references are usually implemented as pointers. 
When we transfer large objects such a matrices and vectors
one should always use call by reference. Copying such objects
to a called function slows down considerably the execution.  If you 
need to keep the value of a call by reference object, you should use the
\verb?const? declaration.
 
In programming languages like Fortran one uses only call by reference, but you can flag
whether a called function or subroutine is allowed or not to change the value by declaring
for example an integer value as \verb?INTEGER, INTENT(IN) ::  i?.  The local function 
cannot change the value of $i$.  Declaring  a transferred values as \verb?INTEGER, INTENT(OUT) ::  i?.
allows the local function to change the variable $i$.


\subsubsection{Initializations and main program}

In every program we have to define the functions employed. The style chosen
here is to declare these functions at the beginning, followed thereafter 
by the main program and the detailed tasks performed by each function.
Another possibility is to include these functions and their statements 
before the main program, meaning that the main program appears at the very end.
I find this programming style less readable however since I prefer to read a code from top to bottom.
A further option, specially in connection with larger projects,
is to include these function definitions in a user defined header file.
The following program shows also (although it is rather unnecessary in this case due to few tasks)
how one can split different tasks into specialized functions. Such a division is very useful for 
larger projects and programs. 


In the first version of this program we use a more C-like style for writing and reading to file.
At the end of this section we include also the corresponding C++ and Fortran files.
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter03/cpp/program1.cpp}}]
/*
**     Program to compute the second derivative of exp(x). 
**     Three calling functions are included
**     in this version. In one function we read in the data from screen,
**     the next function computes the second derivative
**     while the last function prints out data to screen.
*/
using namespace std;
# include  <iostream> 

void initialize (double *, double *, int *);
void second_derivative( int, double, double, double *, double *);
void output( double *, double *, double, int);

int main()
{
        // declarations of variables 
        int number_of_steps;
        double x, initial_step;
	double *h_step, *computed_derivative;
        //  read in input data from screen 
        initialize (&initial_step, &x, &number_of_steps);
	//  allocate space in memory for the one-dimensional arrays  
	//  h_step and computed_derivative                           
        h_step =  new double[number_of_steps];
        computed_derivative = new double[number_of_steps];
	//  compute the second derivative of exp(x) 
        second_derivative( number_of_steps, x, initial_step, h_step, 
                           computed_derivative);        
        //  Then we print the results to file  
	output(h_step, computed_derivative, x, number_of_steps );
        // free memory
        delete [] h_step;
        delete [] computed_derivative; 
        return 0;
}   // end main program 
\end{lstlisting}
 We have defined three additional functions, one which 
reads in from screen the value of $x$, the initial step length $h$
and the number of divisions by 2 of $h$. This function is called
\verb?initialize?. To calculate the second derivatives we define the function 
\verb?second_derivative?. 
Finally, we have a  function which writes our results
together with a comparison with the exact value to a given file.
The results are stored in two arrays, one which contains the 
given step length $h$ and another one which contains 
the computed derivative.

These arrays are defined as pointers through the statement 
\begin{lstlisting}
double *h_step, *computed_derivative;
\end{lstlisting}
A call in the main function to the function 
\verb?second_derivative? 
looks then like this
\begin{lstlisting}
second_derivative( number_of_steps, x, intial_step, h_step, computed_derivative);
\end{lstlisting}
while the called function is declared in the following way
\begin{lstlisting}
void second_derivative(int number_of_steps, double x, double *h_step,double *computed_derivative);
\end{lstlisting}
indicating that
\verb?double  *h_step, double  *computed_derivative;?
are pointers and that we transfer the address of the first elements.
The other variables
\verb?int  number_of_steps, double  x;?
are transferred by value and are not changed in the called function.


Another aspect to observe is the possibility of dynamical allocation of 
memory through the \verb?new? function. In the included program we reserve
space in memory for these three arrays in the following way
\begin{lstlisting}
  h_step = new double[number_of_steps];
  computed_derivative = new double[number_of_steps];
\end{lstlisting}
When we no longer need the space occupied by these arrays, we free
memory through the declarations
\begin{lstlisting}
  delete []  h_step;
  delete []  computed_derivative;
\end{lstlisting}
\subsubsection{The function initialize}

\begin{lstlisting}
//     Read in from screen the initial step, the number of steps 
//     and the value of x 

void initialize (double *initial_step,  double *x, int *number_of_steps)
{
   printf("Read in from screen initial step, x and number of steps\n");
   scanf("%lf %lf %d",initial_step, x, number_of_steps);
   return;
}  // end of function initialize 
\end{lstlisting}

This function receives the addresses of the three variables 
\begin{lstlisting}
void initialize (double *initial_step,  double *x, int *number_of_steps)
\end{lstlisting}
and returns updated values by reading from screen.

\subsubsection{The function second\_derivative}

\begin{lstlisting}
//  This function computes the second derivative 

void second_derivative( int number_of_steps, double x, 
                        double initial_step, double *h_step, 
                        double *computed_derivative)
{
       int counter;
       double h;
       //     calculate the step size  
       //     initialize the derivative, y and x (in minutes) 
       //     and iteration counter 
       h = initial_step;
       //  start computing for different step sizes 
       for (counter=0; counter < number_of_steps; counter++ )  
       {
	  //  setup arrays with derivatives and step sizes
	  h_step[counter] = h;
          computed_derivative[counter] = 
                         (exp(x+h)-2.*exp(x)+exp(x-h))/(h*h);
          h = h*0.5;
	} // end of do loop 
        return;
}   // end of function second derivative 
\end{lstlisting}
The loop over the number of steps serves to compute the 
second derivative 
for different values of $h$. In this function the step is halved
for every iteration (you could obviously change this to larger or smaller step variations). 
The step values and the derivatives are stored
in the arrays 
\verb?h_step? and  \verb?double computed_derivative?.
\subsubsection{The output function}
This function computes the relative error and writes the results to a chosen
file.

The last function here illustrates how to open a file, write and read possible
data and then close it. In this case we have fixed the name of the file.
Another possibility is obviously to read the name of this file together
with other input parameters. The way the program is presented here is 
slightly unpractical since we need to recompile the program if we wish
to change the name of the output file.

An alternative is represented by the following C++ program.
This program reads from screen the names of the input and output
files.
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter03/cpp/program2.cpp}}]
1 #include <stdio.h>
2 #include <stdlib.h>
3 int col:
4
5 int main(int argc, char *argv[])
6 {
7     FILE *inn, *out;
8     int c;
9     if( argc < 3)  {
10    printf("You have to read in :\n");
11    printf("in_file and out_file \n");
12    exit(1);
13    inn = fopen( argv[1], "r");}    // returns pointer to the in_file 
14    if( inn == NULL )  {         // can't find in_file     
15       printf("Can't find the input file %s\n", argv[1]);
16       exit(1);
17    }
18    out = fopen( argv[2], "w");     // returns a pointer to the out_file  
19    if( out == NULL )  {         // can't find out_file     
20       printf("Can't find the output file %s\n", argv[2]);
21       exit(1);
22    }
    ... program statements

23    fclose(inn);
24    fclose(out);
25    return 0;
} 
\end{lstlisting}
This program has several interesting features.
%
{\small
\begin{center}
\begin{tabular}{|ll|}\hline
\hfill Line \hfill
& \hspace*{\fill} Program comments \hspace*{\fill} \\ \hline
&  \\[-2mm]
5 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
The function \verb? main()? takes three arguments, given by \verb?argc?.
The variable \verb?argv? points to the following: the name of the program, the first and second
arguments, in this case the file names to be read from screen.\vspace*{2mm} 
\end{minipage}\\
7 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
C++ has a data type called \verb?FILE?. The pointers \verb?inn? 
and \verb ?out? point to specific files. They must be of the type
\verb?FILE?.
\vspace*{2mm}
\end{minipage}\\
10 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
The command line has to contain 2 filenames as parameters.
\end{minipage}\\
13--17 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
The input file has to exit, else the pointer returns \verb?NULL?.
It has only read permission.
\end{minipage}\\
18--22 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
This applies for the output file as well, but now with write permission only.
\end{minipage}\\ 
23--24 &$\bullet$
\begin{minipage}[t]{0.65\textwidth}
Both files are closed before the main program ends.
\end{minipage}\\[2ex]
\hline
\end{tabular}
\end{center}
} % end small
%


The main part of the code includes now an object declaration \verb?ofstream ofile?
which is included in C++ and allows the programmer to open  and declare files.
This is done via the statement \verb?ofile.open(outfilename);?. We close the file
at the end of the main program by writing \verb?ofile.close();?.
There is a corresponding object for reading inputfiles. In this case we declare prior
to the main function, or in an evantual header file, \verb?ifstream ifile?
and use the corresponding statements \verb?ifile.open(infilename);?
and \verb?ifile.close();? for opening and closing an input file.
Note that we have declared two character variables \verb?char* outfilename;?
and \verb?char* infilename;?. In order to use these options we need to include a 
corresponding library of functions using \verb?# include <fstream>?.

One of the problems with C++ is that formatted output is not as easy to use as 
the printf and scanf functions in C. The output function using the C++ style is included
below.
\begin{lstlisting}
//    function to write out the final results  
void output(double *h_step, double *computed_derivative, double x, 
            int number_of_steps )
{
     int i;
     ofile << "RESULTS:" << endl;
     ofile << setiosflags(ios::showpoint | ios::uppercase);
     for( i=0; i < number_of_steps; i++)
       {
       ofile << setw(15) << setprecision(8) << log10(h_step[i]);
       ofile << setw(15) << setprecision(8) << 
       log10(fabs(computed_derivative[i]-exp(x))/exp(x))) << endl;
        }
}  // end of function output
\end{lstlisting}
The function \verb?setw(15)? reserves an output of 15 spaces for a given variable
while \verb?setprecision(8)? yields eight leading digits. To use these options
you have to use the declaration \verb?# include <iomanip>?.

Before we discuss the results of our calculations we list here the corresponding
Fortran program.
The corresponding Fortran  example is
\lstset{language=[90]Fortran}
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter03/Fortran/program1.f90}}]
!     Program to compute the second derivative of exp(x). 
!     Only one calling function is included.
!     It computes the second derivative and is included in the 
!     MODULE functions as a separate method
!     The variable h is the step size. We also fix the total number
!     of divisions by 2 of h. The total number of steps is read from
!     screen 
MODULE constants
  ! definition of variables for double precisions and complex variables
  INTEGER,  PARAMETER :: dp = KIND(1.0D0)
  INTEGER, PARAMETER :: dpc = KIND((1.0D0,1.0D0))
END MODULE constants

! Here you can include specific functions which can be used by
! many subroutines or functions

MODULE functions
USE constants
IMPLICIT NONE
CONTAINS
  SUBROUTINE derivative(number_of_steps, x, initial_step, h_step, &
       computed_derivative)
    USE constants
    INTEGER, INTENT(IN) :: number_of_steps
    INTEGER  :: loop
    REAL(DP), DIMENSION(number_of_steps), INTENT(INOUT) :: &
         computed_derivative, h_step
    REAL(DP), INTENT(IN) :: initial_step, x 
    REAL(DP) :: h
    !     calculate the step size  
    !     initialize the derivative, y and x (in minutes) 
    !     and iteration counter 
    h = initial_step
    ! start computing for different step sizes 
    DO loop=1,  number_of_steps
       !  setup arrays with derivatives and step sizes
       h_step(loop) = h
       computed_derivative(loop) = (EXP(x+h)-2.*EXP(x)+EXP(x-h))/(h*h)
       h = h*0.5
    ENDDO
  END SUBROUTINE derivative

END MODULE functions

PROGRAM second_derivative
  USE constants
  USE functions
  IMPLICIT NONE
  ! declarations of variables 
  INTEGER :: number_of_steps, loop
  REAL(DP) :: x, initial_step
  REAL(DP), ALLOCATABLE, DIMENSION(:) :: h_step, computed_derivative
  !  read in input data from screen 
  WRITE(*,*) 'Read in initial step, x value and number of steps'
  READ(*,*) initial_step, x, number_of_steps
  ! open file to write results on
  OPEN(UNIT=7,FILE='out.dat')
  !  allocate space in memory for the one-dimensional arrays  
  !  h_step and computed_derivative                           
  ALLOCATE(h_step(number_of_steps),computed_derivative(number_of_steps))
  ! compute the second derivative of exp(x)
  ! initialize the arrays
  h_step = 0.0_dp; computed_derivative = 0.0_dp 
  CALL  derivative(number_of_steps,x,initial_step,h_step,computed_derivative)

  !  Then we print the results to file  
  DO loop=1,  number_of_steps
     WRITE(7,'(E16.10,2X,E16.10)') LOG10(h_step(loop)),&
     LOG10 ( ABS ( (computed_derivative(loop)-EXP(x))/EXP(x)))
  ENDDO
  ! free memory
  DEALLOCATE( h_step, computed_derivative)
  ! close the output file
  CLOSE(7)
 
END PROGRAM second_derivative
\end{lstlisting}
The \verb?MODULE? declaration in Fortran allows one to place functions
like the one which calculates second derivatives in a module. Since this is a general method,
one could extend its functionality by simply transfering 
the name of the function to differentiate. In our case we use explicitely the exponential
function, but there is nothing which hinders us from defining other functions. 
Note the usage of the module {\bf constants} where we define double and complex variables.
If one wishes to switch to another precision, one needs to change the declaration
in one part of the program only. This hinders possible errors which arise if one has to change
variable declarations in every function and subroutine.   
Finally, dynamic memory allocation and deallocation is in Fortran 
done with the keywords \verb?ALLOCATE( array(size))? and \verb?DEALLOCATE(array)?.
Although most compilers deallocate and thereby free space in memory when leaving a
function, you should always deallocate an array when it is no longer needed. In case your arrays
are very large, this may block unnecessarily large fractions of the memory. 
Furthermore, you should always initialize arrays. In the example above, we note that Fortran allows
us to simply write \verb?h_step = 0.0_dp; computed_derivative = 0.0_dp?, which means that all
elements of these two arrays are set to zero.  Coding arrays in this manner brings us much
closer to the way we deal with mathematics. 
In Fortran  it is irrelevant whether this is a one-dimensional or multi-dimensional array.
In chapter \ref{chap:linalgebra}, where we deal with
allocation of matrices, we will introduce the  numerical libraries Armadillo and 
Blitz++ which allow for similar
treatments of arrays in C++. By default however, these features are not included in 
the ANSI C++ standard. 

\subsubsection{Results}
In Table \ref{tab:secderivchap3} we present the results 
of a {\em numerical evaluation }
for various step sizes for the second
derivative  of $\exp{(x)}$ using the approximation  
$f_0''=\frac{ f_h -2f_0 +f_{-h}}{h^2}$. The results are 
compared with the exact ones for various $x$ values.
\begin{table}[hbtp]
\begin{center}
\begin{tabular}{rrrrrrr}\hline
$x$&$h=0.1$&$h=0.01$&$h=0.001$&$h=0.0001$&$h=0.0000001$ &Exact\\\hline
  0.0&  1.000834 &   1.000008 &   1.000000 &   1.000000 &   1.010303 &   1.000000  \\ 
 1.0&    2.720548 &   2.718304  &  2.718282  &  2.718282  &  2.753353  &  2.718282  \\
 2.0&   7.395216  &  7.389118  &  7.389057  &  7.389056  &  7.283063  &  7.389056  \\
 3.0&    20.102280 &  20.085704 &  20.085539 &  20.085537 &  20.250467 &  20.085537   \\
 4.0&   54.643664 &  54.598605 &  54.598155  & 54.598151 &  54.711789  & 54.598150  \\
 5.0&   148.536878 & 148.414396 & 148.413172 & 148.413161 & 150.635056 & 148.413159 \\\hline
\end{tabular} 
\caption{Result  for numerically calculated second derivatives of $\exp{(x)}$ as functions of the 
chosen step size $h$.  A comparison is made
         with the exact value. \label{tab:secderivchap3}}
\end{center}   
\end{table}     
Note well that as the step is decreased we get closer to the exact value. However,
if it is further decreased, we run into problems of loss of precision. This is clearly seen
for $h=0.0000001$.
This means that even though we could let the computer run with smaller and smaller
values of the step, there is a limit for how small the step can be made before we
loose precision.  

\subsection{Error analysis}

Let us analyze these results in order to see whether we can find
a minimal step length which does not lead to loss of precision.
Furthermore 
In Fig.~\ref{fig:lossofprecision} we have plotted
\[
   \epsilon=log_{10}\left(\left|\frac{f''_{\mathrm{computed}}-f''_{\mathrm{exact}}}
                 {f''_{\mathrm{exact}}}\right|\right),
\]
as function of $log_{10}(h)$. 
We used an intial step length of $h=0.01$ and fixed $x=10$.
For large values of $h$, that is $-4 < log_{10}(h) < -2$  we see 
a straight line with a slope close to 2. Close to
$log_{10}(h) \approx -4$
the relative error starts increasing and our computed derivative with 
a step size $log_{10}(h)<  -4$, may no longer be reliable.
\begin{figure}
\begin{center}
\input{figures/lossofprecision}
\end{center}
\caption{Log-log plot of the relative error of the second derivative of $\exp{(x)}$ 
as function of decreasing step lengths $h$. The second derivative
was computed for $x=10$ in the program discussed above. See text for
further details\label{fig:lossofprecision}}
\end{figure}

Can we understand this behavior in terms of the discussion from the previous
chapter?
In chapter \ref{chap:numanalysis} we assumed that the total error
could be approximated with one term arising from the loss of numerical
precision and another due to the truncation or approximation made,
that is
\[
   \epsilon_{\mathrm{tot}}=\epsilon_{\mathrm{approx}}+\epsilon_{\mathrm{ro}}.
\]

For the computed second derivative, Eq.\ (\ref{eq:seconderivative}), we have 
\[
 f_0''=\frac{ f_h -2f_0 +f_{-h}}{h^2}-2\sum_{j=1}^{\infty}\frac{f_0^{(2j+2)}}{(2j+2)!}h^{2j},
\]
and the truncation or approximation error goes like
\[
  \epsilon_{\mathrm{approx}}\approx \frac{f_0^{(4)}}{12}h^{2}.
\]
If we were not to worry about loss of precision, we could in principle
make $h$ as small as possible. 
However, due to the computed expression in the above program example
\[
 f_0''=\frac{ f_h -2f_0 +f_{-h}}{h^2}=\frac{ (f_h -f_0) +(f_{-h}-f_0)}{h^2},
\]
we reach fairly quickly a limit for where loss of precision due to the subtraction
of two nearly equal numbers becomes crucial. 
If $(f_{\pm h} -f_0)$ are very close, we have
$(f_{\pm h} -f_0)\approx \epsilon_M$, where $|\epsilon_M|\le 10^{-7}$ for single and
$|\epsilon_M|\le 10^{-15}$ for double precision, respectively.

We have then
\[
 \left|f_0''\right|=
 \left|\frac{ (f_h -f_0) +(f_{-h}-f_0)}{h^2}\right|\le \frac{ 2 \epsilon_M}{h^2}.
\]
Our total error becomes 
\begin{equation}
   \left|\epsilon_{\mathrm{tot}}\right|\le  \frac{2 \epsilon_M}{h^2} + 
                          \frac{f_0^{(4)}}{12}h^{2}. 
    \label{eq:experror}
\end{equation}
It is then natural to ask which value of $h$ yields the smallest
total error. Taking the derivative of $\left|\epsilon_{\mathrm{tot}}\right|$
with respect to $h$ results in
\[
   h= \left(\frac{ 24\epsilon_M}{f_0^{(4)}}\right)^{1/4}.
\]
With double precision and $x=10$ we obtain 
\[
   h\approx 10^{-4}.
\] 
Beyond this value, it is essentially the loss of numerical precision
which takes over. 
We note also that the above qualitative argument agrees seemingly well 
with the results plotted in Fig.\ \ref{fig:lossofprecision} and Table
\ref{tab:secderivchap3}. The turning point for the relative error at
approximately  $h\approx  10^{-4}$ reflects most likely the point
where roundoff errors take over. If we had used single precision, we would get
$h\approx 10^{-2}$. Due to the subtractive cancellation in the expression
for $f''$ there is a pronounced detoriation in accuracy as $h$ is made smaller
and smaller. 

It is instructive in this analysis to rewrite the numerator of
the computed derivative as
\[
   (f_h -f_0) +(f_{-h}-f_0)=(\exp{(x+h)}-\exp{x}) + (\exp{(x-h)}-\exp{x}),
\]
as
\[
   (f_h -f_0) +(f_{-h}-f_0)=\exp{(x)}(\exp{(h)}+\exp{(-h)}-2),
\]
since it is the difference $(\exp{(h)}+\exp{(-h)}-2)$ which causes
the loss of precision.
The results, still for $x=10$ are shown in the Table
\ref{tab:subcancellation}.
\begin{table}[hbtp]
\begin{center}
\begin{tabular}{lll}\hline
$h$&$\exp{(h)}+\exp{(-h)}$ & $\exp{(h)}+\exp{(-h)}-2$\\\hline
 $10^{-1}$ & 2.0100083361116070 &  1.0008336111607230$\times 10^{-2}$ \\
 $10^{-2}$ & 2.0001000008333358 &  1.0000083333605581$\times 10^{-4}$ \\
 $10^{-3}$ & 2.0000010000000836 &  1.0000000834065048$\times 10^{-6}$ \\
 $10^{-4}$ & 2.0000000099999999 &  1.0000000050247593$\times 10^{-8}$ \\
 $10^{-5}$ & 2.0000000001000000 &  9.9999897251734637$\times 10^{-11}$  \\
 $10^{-6}$ & 2.0000000000010001 &  9.9997787827987850$\times 10^{-13}$  \\
 $10^{-7}$ & 2.0000000000000098 &  9.9920072216264089$\times 10^{-15}$  \\
 $10^{-8}$ & 2.0000000000000000 &  0.0000000000000000$\times 10^{0}$ \\
 $10^{-9}$ & 2.0000000000000000 &  1.1102230246251565$\times 10^{-16}$  \\
 $10^{-10}$  & 2.0000000000000000 &  0.0000000000000000$\times 10^{0}$ \\
&&\\\hline
\end{tabular} 
\caption{Result  for the numerically calculated numerator of the second derivative  
         as function of the step size $h$. The calculations have been made
with double precision.\label{tab:subcancellation}}
\end{center}   
\end{table}     
We note from this table that at $h\approx \times 10^{-8}$ we have
essentially lost all leading digits.

 From  Fig.~\ref{fig:lossofprecision}
we can read off  the slope of the curve and thereby determine 
empirically how truncation errors and roundoff errors propagate.
We saw that for  $-4 < log_{10}(h) < -2$, we could extract a slope
close to $2$, in agreement with the mathematical expression
for the truncation error.
 
We can repeat this for $-10 < log_{10}(h) < -4$ and extract a
slope which is  approximately equal to $-2$. This agrees again with our simple expression
in Eq.~(\ref{eq:experror}).


%  last update  26/08/2003  mhj


\section{Numerical Interpolation and Extrapolation}


Numerical interpolation and extrapolation are frequently 
used tools in numerical applications to physics. The often encountered
situation is that of a function $f$ at a set of points $x_1\dots x_n$ where
an analytic form is missing. The function $f$ may represent some data points
from experiment or the result of a lengthy large-scale computation of some
physical quantity that cannot be cast into a simple analytical form.

We may then need to evaluate the function $f$ at some point $x$  within  
the data set $x_1\dots x_n$, but where $x$ differs from the tabulated values.
In this case we are dealing with interpolation. If $x$ is outside 
we are left with the more troublesome problem of numerical extrapolation.
Below we will concentrate on two methods for interpolation and 
extrapolation, namely
polynomial interpolation and extrapolation.
The cubic spline interpolation approach is discussed in chapter \ref{chap:linalgebra}.



\subsection{Interpolation} \label{subsec:interpol}

%\subsection{Polynomial interpolation and extrapolation}
 Let us assume that we have a set of $N+1$ points 
$y_0=f(x_0),y_1=f(x_1),\dots,y_N=f(x_N)$ where none of the $x_i$ values are equal.
We wish to determine
a polynomial of degree $n$ so that
\be
  P_N(x_i)=f(x_i)=y_i, \hspace{1cm} i=0,1,\dots, N
  \label{eq:poly1}
\ee
for our data points. 
If we then write $P_N$ on the form
\be
   P_N(x)=a_0+a_1(x-x_0)+a_2(x-x_0)(x-x_1) + \dots+ a_N(x-x_0)\dots(x-x_{N-1}),
   \label{eq:poly2}
\ee
then Eq.\ (\ref{eq:poly1}) results in a triangular system of equations
\[
      \begin{array}{ccccc} a_0&=f(x_0)  &  &  \\
                           a_0+&a_1(x_1-x_0)&=f(x_1) &  \\
                           a_0+&a_1(x_2-x_0)+&a_2(x_2-x_0)(x_2-x_1)&=f(x_2)  \\
                           \dots & \dots &\dots & \dots \end{array}.
\]
The coefficients $a_0,\dots,a_N$ are then determined in a recursive way,
starting with $a_0,a_1,\dots$. 

The classic of interpolation formulae was created by Lagrange and is given by
\begin{equation}
   P_N(x)=\sum_{i=0}^{N}\prod_{k\ne i} \frac{x-x_k}{x_i-x_k}y_i.
\label{eq:lagrange}
\end{equation}

If we have just two points (a straight line) we get
\[
   P_1(x)=\frac{x-x_0}{x_1-x_0}y_1+\frac{x-x_1}{x_0-x_1}y_0,
\]
and with three points (a parabolic approximation) we have
\[
     P_3(x)=\frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)}y_2+
            \frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)}y_1+
            \frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)}y_0
\]
and so forth. It is easy to see from the above equations that when
$x=x_i$ we have that $f(x)=f(x_i)$
It is also possible to show that the approximation error (or rest term) is given by
the second term on the right hand side of 
\be
    f(x)=P_N(x)+\frac{\omega_{N+1}(x)f^{(N+1)}(\xi)}{(N+1)!}.
    \label{eq:poly3}
\ee
The function $\omega_{N+1}(x)$ is given by
\[
   \omega_{N+1}(x)=a_N(x-x_0)\dots(x-x_{N}),
\]
and $\xi=\xi(x)$ is a point in the smallest interval containing 
all interpolation points $x_j$ and $x$. 
The program we provide below 
is however based on divided differences. The recipe is quite simple. If we take
$x=x_0$ in Eq.\ (\ref{eq:poly2}), we then have obviously that 
$a_0=f(x_0)=y_0$. Moving $a_0$ over to the left-hand  side and dividing
by $x-x_0$ we have
\[
   \frac{f(x)-f(x_0)}{x-x_0}=a_1+a_2(x-x_1) + \dots+ a_N(x-x_1)(x-x_2)\dots(x-x_{N-1}),
\]
where we hereafter omit the rest term 
\[ 
   \frac{f^{(N+1)}(\xi)}{(N+1)!}(x-x_1)(x-x_2)\dots(x-x_{N}).
\]
The quantity
\[
   f_{0x}=\frac{f(x)-f(x_0)}{x-x_0},
\]
is a divided difference of first order. If we then take $x=x_1$, we have that
$a_1=f_{01}$. Moving $a_1$ to the left again and dividing by $x-x_1$ we obtain
\[ 
   \frac{f_{0x}-f_{01}}{x-x_1}=a_2 + \dots+ a_N(x-x_2)\dots(x-x_{N-1}).
\]
and the quantity 
\[
   f_{01x}=\frac{f_{0x}-f_{01}}{x-x_1},
\]
is a divided difference of second order. We note that the coefficient
\[ 
   a_1=f_{01},
\] 
is determined from $f_{0x}$ by setting $x=x_1$. We can continue along this line
and define the divided difference of order $k+1$ as 
\be
   f_{01\dots kx}=\frac{f_{01\dots (k-1)x}-f_{01\dots(k-1)k}}{x-x_k},
   \label{eq:divdiff}
\ee
meaning that the corresponding coefficient $a_k$ is given by
\[ 
   a_k=f_{01\dots(k-1)k}.
\]
With these definitions we see that Eq.\ (\ref{eq:poly3}) can be rewritten as
\[
        f(x)=a_0+\sum_{k=1}{N}f_{01\dots k}(x-x_0)\dots(x-x_{k-1})+\frac{\omega_{N+1}(x)f^{(N+1)}(\xi)}{(N+1)!}.   
\]
If we replace $x_0,x_1,\dots,x_k$ in Eq.\ (\ref{eq:divdiff}) with 
$x_{i+1},x_{i+2},\dots,x_k$, that is we count from $i+1$ to $k$ instead of counting 
from $0$ to $k$ and replace $x$ with $x_i$, we can then construct the following recursive
algorithm for the calculation of divided differences
\[
   f_{x_ix_{i+1}\dots x_k}=\frac{f_{x_{i+1}\dots x_k}-f_{x_ix_{i+1}\dots x_{k-1}}}{x_k-x_i}.
\]
Assuming that we have a table with function values $(x_j, f(x_j)=y_j)$ and need to construct
the coefficients for the polynomial $P_N(x)$. We can then view the last equation
by constructing the following table for the case where $N=3$.
\[
      \begin{array}{cccccc} x_0&y_0  &          &  & \\
                              &      &f_{x_0x_1}  &  &  \\
                            x_1&y_1  &          & f_{x_0x_1x_2} &  \\
                              &      &f_{x_1x_2}  &  &f_{x_0x_1x_2x_3}  \\
                            x_2&y_2  &  & f_{x_1x_2x_3} &  \\
                              &      &f_{x2x_3}  &  &  \\
                            x_3&y_3  &  & \end{array}.
\]
The coefficients we are searching for will then be the elements along the main diagonal.
We can understand this algorithm by considering the following. First we construct 
the unique polynomial of order zero which passes through the point $x_0,y_0$. This is just
$a_0$ discussed above. Therafter we construct the unique polynomial of order one
which passes through both $x_0y_0$ and $x_1y_1$. This corresponds to the coefficient 
$a_1$ and the tabulated value $f_{x_0x_1}$ and together with $a_0$ results in the polynomial
for a 
straight line. Likewise we define polynomial coefficients for all other couples of points
such as    $f_{x_1x_2}$ and $f_{x_2x_3}$. Furthermore, a coefficient like $a_2=f_{x_0x_1x_2}$
spans now three points, and adding together $f_{x_0x_1}$ we obtain a polynomial
which represents three points, a parabola. In this fashion we can continue
till we have all coefficients. The function we provide below included is based
on an extension of this algorithm, knowns as Neville's algorithm. 
%  MHJ Oct/11/2011
%  add more math about Neville's algorithm
The error provided by Neville's algorithm 
is based on the truncation error in Eq.~(\ref{eq:poly3}).
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter03/cpp/program4.cpp}}]
   /*
   ** The function
   **            polint()
   ** takes as input xa[0,..,n-1] and ya[0,..,n-1] together with a given value
   ** of x and returns a value y and an error estimate dy. If P(x) is a polynomial
   ** of degree N - 1 such that P(xa_i) = ya_i, i = 0,..,n-1, then the returned 
   ** value is y = P(x). 
   */
void polint(double xa[], double ya[], int n, double x, double *y, double *dy)
{
  int      i, m, ns = 1;
  double   den,dif,dift,ho,hp,w;
  double   *c,*d;
  
  dif = fabs(x - xa[0]);
  c = new double [n];
  d = new double [n];
  for(i = 0; i < n; i++) {
      if((dift = fabs(x - xa[i])) < dif) {
         ns  = i;
	 dif = dift;
      }
      c[i] = ya[i];
      d[i] = ya[i];
  }
  *y = ya[ns--];
  for(m = 0; m < (n - 1); m++) {
     for(i = 0; i < n - m; i++) {
         ho = xa[i] - x;
         hp = xa[i + m] - x;
         w  = c[i + 1] - d[i];
         if((den = ho - hp) < ZERO) {
            printf("\n\n Error in function polint(): ");
            printf("\nden = ho - hp = %4.1E -- too small\n",den);
            exit(1);
	 }
         den  = w/den;
         d[i] = hp * den;
         c[i] = ho * den;
      }
      *y += (*dy = (2 * ns < (n - m) ? c[ns + 1] : d[ns--]));
   }
   delete [] d;
   delete [] c;
} // End: function polint()
\end{lstlisting}
When using this function, you need obviously to declare the function itself.  

\subsection{Richardson's deferred extrapolation method}\label{subsec:rich}

Here we present an elegant method to improve the precision of our mathematical truncation, without
too many additional function evaluations.  We will again study
the evaluation of the first and second derivatives of $\exp{(x)}$ at a given 
point $x=\xi$.
In Eqs.~(\ref{eq:firstderivative}) and (\ref{eq:seconderivative})
for the first and second 
derivatives, 
we noted that
the truncation error goes like $O(h^{2j})$. 

Employing the mid-point approximation to the derivative, 
the various derivatives $D$ of a given function $f(x)$ can then be written as 
\[
  D(h)=D(0)+a_1h^2+a_2h^4+a_3h^6+\dots,
\]
where $D(h)$ is the calculated derivative, $D(0)$ the exact value 
in the limit $h\rightarrow 0$ and $a_i$ are independent of $h$. 
By choosing smaller and smaller values for $h$, we should
in principle be able to approach the exact value. However, since the derivatives involve differences,
we may easily loose numerical precision as shown in the previous sections.
A possible cure is to apply Richardson's deferred approach, i.e., 
we perform calculations with several values of the step $h$ and extrapolate to $h=0$.
The philososphy is to combine different values of $h$ so that the terms in the above equation involve only
large exponents for $h$. To see this, assume that we mount a calculation for two
values of the step $h$, one with $h$ and the other with $h/2$. 
Then we have
\[
   D(h)=D(0)+ a_1h^2+a_2h^4+a_3h^6+\dots,
\]
and
\[
   D(h/2)=D(0)+ \frac{a_1h^2}{4}+\frac{a_2h^4}{16}+\frac{a_3h^6}{64} +\dots,
\]
and we can eliminate the term with $a_1$ by combining
\be
D(h/2)+\frac{D(h/2)-D(h)}{3}=D(0)-\frac{a_2h^4}{4}-\frac{5a_3h^6}{16}.
\label{eq:lesserror}
\ee
We see that this approximation to $D(0)$ is better than the two previous ones since
the error now goes like $O(h^4)$. 
As an example, let us evaluate the first derivative of a function $f$ 
using a step with lengths $h$ and  $h/2$. We have then
\[
   \frac{f_h-f_{-h}}{2h}=f'_0+O(h^2),
\]
\[
   \frac{f_{h/2}-f_{-h/2}}{h}=f'_0+O(h^2/4),
\]
which can be combined, using Eq.\ (\ref{eq:lesserror}) to yield
\[
\frac{-f_h+8f_{h/2}-8f_{-h/2}+f_{-h}}{6h}=f'_0-\frac{h^4}{480}f^{(5)}.
\]

In practice, what happens is that our approximations to $D(0)$ goes through a series of steps
\[
      \begin{array}{ccccc} D_0^{(0)} &  &  &  \\
                           D_0^{(1)} & D_1^{(0)} & &  \\
                           D_0^{(2)} & D_1^{(1)} &D_2^{(0)} &  \\
                           D_0^{(3)} & D_1^{(2)} &D_2^{(1)} & D_3^{(0)}  \\
                           \dots & \dots &\dots & \dots \end{array} ,
\]
where the elements in the first column represent the given approximations
\[
    D_0^{(k)}=D(h/2^k).
\]
This means that $D_1^{(0)}$ in the second column and row is the result
of the extrapolation based on $D_0^{(0)}$ and $D_0^{(1)}$.
An element $D_m^{(k)}$ in the table is then given by
\be
   D_m^{(k)}=D_{m-1}^{(k)}+ \frac{D_{m-1}^{(k+1)}-D_{m-1}^{(k)}}{4^m-1}
   \label{eq:richardsson_ext}
\ee
with $m > 0$. 

In Table \ref{tab:secderivchap3}
we presented the results for various step sizes for the second
derivative  of $\exp{(x)}$ using 
$f_0''=\frac{ f_h -2f_0 +f_{-h}}{h^2}$. The results were 
compared with the exact ones for various $x$ values.
Note well that as the step is decreased we get closer to the exact value. However,
if it is further increased, we run into problems of loss of precision. This is clearly seen
for $h=0.000001$.
This means that even though we could let the computer run with smaller and smaller
values of the step, there is a limit for how small the step can be made before we
loose precision. 
Consider now the results in Table \ref{tab:richardson} 
where we choose to employ
Richardson's extrapolation scheme. In this calculation we have 
computed our function with only three possible values for the step size, namely $h$, $h/2$ and $h/4$
with $h=0.1$. The agreement with the exact value is amazing! 
The extrapolated result is based upon the use of Eq.~(\ref{eq:richardsson_ext}).
\begin{table}[hbtp]
\begin{center}
\begin{tabular}{rrrrrr}\hline
$x$&$h=0.1$&$h=0.05$&$h=0.025$&Extrapolat&Error \\\hline
  0.0& 1.00083361 &   1.00020835  &  1.00005208  &  1.00000000  &  0.00000000    \\
 1.0&  2.72054782  &  2.71884818  &  2.71842341  &  2.71828183  &  0.00000001   \\
 2.0&  7.39521570  &  7.39059561  &  7.38944095  &  7.38905610  &  0.00000003    \\
 3.0&   20.10228045 &  20.08972176 &  20.08658307 &  20.08553692 &   0.00000009  \\ 
 4.0&    54.64366366 &  54.60952560 &  54.60099375 &  54.59815003 &   0.00000024  \\
 5.0&   148.53687797&  148.44408109 & 148.42088912 & 148.41315910  &  0.00000064 \\\hline
\end{tabular}  
\caption{Result  for numerically calculated second derivatives of $\exp{(x)}$ using
         extrapolation. The first three values are those calculated with three different
         step sizes, $h$, $h/2$ and $h/4$ with $h=0.1$. The extrapolated result to $h=0$
         should then be compared with the exact ones from Table \ref{tab:secderivchap3}. \label{tab:richardson}} 
\end{center}  
\end{table}     
An alternative recipe is to use our function for the polynomial extrapolation discussed in the previous
subsection and calculate the derivatives for several values of $h$ and then extrapolate to $h=0$.
We will use this method to obtain improved eigenvalues in chapter \ref{chap:eigenvalue}.

Other methods to interpolate a function $f(x)$ such as spline methods 
will be discussed in chapter \ref{chap:linalgebra}.


\section{Classes in C++}\label{section:classes}

In Fortran a vector (this applies to matrices as well) starts with $1$, but it is easy 
to change the declaration of  vector so that it starts with zero or even a negative number.
If we have a double precision Fortran vector  which starts at $-10$ and ends at $10$, we could declare it as 
\verb?REAL(KIND=8) ::  vector(-10:10)?. Similarly, if we want to start at zero and end at 10 we could write
\verb?REAL(KIND=8) ::  vector(0:10)?.  
Fortran  allows us to write a vector addition ${\bf a} = {\bf b}+{\bf c}$ as
\verb?a = b + c?.  This means that we have overloaded the addition operator in order to translate this operation into
two loops and an addition of two vector elements $a_{i} = b_{i}+c_{i}$.

The way the vector addition is written is very close to the way we express this relation mathematically. The benefit for the 
programmer is that our code is easier to read. Furthermore, such a way of coding makes it  more likely  to spot eventual 
errors as well.  


In Ansi C and C++ arrays start by default from $i=0$.  Moreover, if we  wish to add two vectors we need to explicitely write out
a loop as
\lstset{language=c++}  
\begin{lstlisting}
for(i=0 ; i < n ; i++) {  
   a[i]=b[i]+c[i]
}  
\end{lstlisting} 

However, 
the strength of C++ over programming languages like C and Fortran 77 is the possibility 
to define new data types, tailored to some particular problem.
Via new data types and overloading of operations such as addition and subtraction, we can easily define 
sets of operations and data types which allow us to write a vector or 
matrix addition in exactly the same
way as we would do in Fortran.  We could also change the way we declare a C++ vector (or matrix)  element $a_{i}$, from  $a[i]$ 
to say $a(i)$, as we would do in Fortran. Similarly, we could also change the default range from $0:n-1$ to $1:n$. 

To achieve this we need to introduce two important entities in C++ programming, classes and templates.        



The function and class declarations are fundamental concepts within C++.  Functions are abstractions
which encapsulate an algorithm or parts of it and perform specific tasks in a program. 
We have already met several examples on how to use  functions. 
Classes can be defined as abstractions which encapsulate
data and operations on these data. 
The data can be very complex data structures  and the class can contain particular functions
which operate on these data. Classes allow therefore for a higher level of abstraction in computing.
The elements (or components) of the data
type are the class data members, and the procedures are the class
member functions. 

Classes are user-defined tools used to create multi-purpose software which can be reused by other classes or functions.
These user-defined data types contain data (variables) and 
functions operating on the data.  

A simple example is that of a point in two dimensions.  
The data could be the $x$ and $y$ coordinates of a given  point. The functions
we define could be simple read and write functions or the possibility to compute the distance between two points.

The two examples we  elaborate on below demonstrate most of the features of classes. 
We develop first a class called \verb?Complex?  which allows us to perform various operations on 
complex variables.
We extend thereafter our discussion of classes to
define a class \verb?Vector? 
which allows us to perform various operations on a user-specified one-dimesional array, from
declarations of a vector to mathematical operations such as additions of vectors. Later, in our discussion on linear algebra, we will also present our final matrix and vector class.

The classes we define are easy to use in other codes and/or other classes and many of the details 
which would be present in C (or Fortran 77) codes are hidden inside
the class.  The reuse of a well-written and functional class is normally rather simple.
However, to write a given class is often complicated, especially if we deal with complicated 
matrix operations.  In this text we will rely on ready-made classes in C++  for dealing
with matrix operations.  We have chosen to use the libraries like Armadillo or Blitz++, 
discussed in our linear algebra chapter. 
These libraries hide  many low-level operations  with matrices  and vectors, such as
matrix-vector multiplications or allocation and deallocation of memory.    
Such libraries make it then easier
to build our own high-level classes out of well-tested
lower-level classes.

The way we use classes in this text is close to the \verb?MODULE? data type in Fortran and we provide 
some simple demonstrations at the end of this section.

\subsection{The Complex class}

As remarked in chapter \ref{chap:numanalysis}, 
C++ has a class complex in its standard
template library (STL). The standard usage in a given function could then look like 
\begin{lstlisting}
// Program to calculate addition and multiplication of two complex numbers
using namespace std;
#include <iostream>
#include <cmath>
#include <complex>
int main()
{
  complex<double> x(6.1,8.2), y(0.5,1.3);
  // write out x+y
  cout << x + y << x*y  << endl;
  return 0;
}
\end{lstlisting}
where we add and multiply two complex numbers $x=6.1+\imath 8.2$ and $y=0.5+\imath 1.3$ with the obvious results
$z=x+y=6.6+\imath 9.5$ and $z=x\cdot y= -7.61+\imath 12.03$. 
In Fortran we would declare the above variables as 
\verb?COMPLEX(DPC) :: x(6.1,8.2), y(0.5,1.3)?. 

The libraries Armadillo and Blitz++ include an extension of the 
complex class to operations on vectors, matrices and higher-dimensional arrays. We recommend the usage of such libraries 
when you develop your own codes.  
However, writing  a complex  class yourself is a good pedagogical exercise.  

We proceed by  splitting our task in three files.  
\begin{itemize}
\item We define first a header file complex.h  which contains the declarations of
the class. The header file contains the class declaration (data and
functions), declaration of stand-alone functions, and all inlined
functions, starting as follows
\begin{lstlisting}
#ifndef Complex_H
#define Complex_H
//   various include statements and definitions
#include <iostream>          // Standard ANSI-C++ include files
#include <new>
#include ....

class Complex
{...
definition of variables and their character
};
//   declarations of various functions used by the class
...
#endif
\end{lstlisting}
\item Next we provide a file complex.cpp where the code and algorithms of different functions  (except inlined functions) 
declared within the class are written.
The files complex.h and complex.cpp are normally placed in a directory with other classes and libraries we have 
defined.  
\item Finally,we discuss here an example of a main program which uses this particular class.
An example of a program which uses our complex class is given below. In particular we would like our class to
perform tasks like declaring complex variables, writing out the real and imaginary part and performing 
algebraic operations such as adding or multiplying two complex numbers.
\begin{lstlisting}
#include "Complex.h"
...  other include and declarations
int main ()
{
  Complex a(0.1,1.3);    // we declare a complex variable a
  Complex b(3.0), c(5.0,-2.3);  // we declare  complex variables b and c
  Complex d = b;         //  we declare  a new complex variable d 
  cout << "d=" << d << ", a=" << a << ", b=" << b << endl;
  d = a*c + b/a;  //   we add, multiply and divide two complex numbers 
  cout << "Re(d)=" << d.Re() << ", Im(d)=" << d.Im() << endl;  // write out of the real and imaginary parts
}
\end{lstlisting}
We include the header file complex.h and define four different complex variables. These
are $a=0.1+\imath 1.3$, $b=3.0+\imath 0$ (note that if you don't define a value for the imaginary part  this is set to
zero), $c=5.0-\imath 2.3$ and $d=b$.  Thereafter we have defined standard algebraic operations and the member functions
of the class which allows us to print out the real and imaginary part of a given variable.
\end{itemize}

To achieve these features, let us see how we  define the complex class.
In C++ we could define a complex class as follows
\begin{lstlisting}
class Complex
{
private:
   double re, im; // real and imaginary part
public:
   Complex ();                              // Complex c;
   Complex (double re, double im = 0.0); // Definition of a complex variable;
   Complex (const Complex& c);              // Usage: Complex c(a);   // equate two complex variables
   Complex& operator= (const Complex& c); // c = a;   //  equate two complex variables, same as previous
  ~Complex () {}                        // destructor
   double   Re () const;        // double real_part = a.Re();
   double   Im () const;        // double imag_part = a.Im();
   double   abs () const;       // double m = a.abs(); // modulus
   friend Complex operator+ (const Complex&  a, const Complex& b);
   friend Complex operator- (const Complex&  a, const Complex& b);
   friend Complex operator* (const Complex&  a, const Complex& b);
   friend Complex operator/ (const Complex&  a, const Complex& b);
};
\end{lstlisting}

The class is defined via the statement \verb?class Complex?. We must first use the key word 
\verb?class?, which in turn is followed by the user-defined variable name  \verb?Complex?. 
The body of the class, data and functions, is encapsulated  within the parentheses $\{...\};$.

Data and specific functions can be private, which means that they cannot be accessed from outside the class.
This means also that access cannot be inherited by other functions outside the class. If we use \verb?protected?
instead of \verb?private?, then data and functions can be inherited outside the class.
The key word \verb?public? means  that data and functions can be accessed from outside the class.
Here we have defined several functions  which can be accessed by functions outside the class.
The declaration \verb?friend? means that stand-alone functions can work on privately declared  variables  of the type
\verb?(re, im)?.  Data members of a class should be declared as private variables.


The first public function we encounter is a so-called   
constructor, which  tells how we declare a variable of type \verb?Complex? 
and how this variable is initialized. We have chosen  three possibilities in the example above:
\begin{enumerate}
\item A declaration like \verb?Complex c;? calls the member function \verb?Complex()?
which can have the following implementation 
\begin{lstlisting}
Complex:: Complex ()   { re = im = 0.0; }
\end{lstlisting}
meaning that it sets the real and imaginary parts to zero.  Note the way a member function is defined.
The constructor is the first function that is called when an object is instantiated.
\item Another possibility  is 
\begin{lstlisting}
Complex:: Complex ()   {}
\end{lstlisting}
which means that there is no initialization of the real and imaginary parts.  The drawback is that a given compiler
can then assign random values to a given variable.
\item  A call like \verb?Complex a(0.1,1.3);? means that we could call the member function 
as
\begin{lstlisting}
Complex:: Complex (double re_a, double im_a)
{ re = re_a; im = im_a; }
\end{lstlisting}
\end{enumerate}


The simplest member function are those we defined to extract 
the real and imaginary part of a variable. Here you have to recall that these are private data,
that is they are invisible for users of the class.  We obtain a copy of these variables by defining the 
functions
\begin{lstlisting}
double Complex:: Re () const { return re; }} //  getting the real part
double Complex:: Im () const { return im; }  //   and the imaginary part
\end{lstlistingline}
Note that we have introduced   the declaration  \verb?const}.  What does it mean? 
This declaration means that a variable cannot be changed within  a called function.
If we define a variable as 
\verb?const double p = 3;? and then try to change its value, we will get an error when we
compile our program. This means that constant arguments in functions cannot be changed.
\begin{lstlisting}
// const arguments (in functions) cannot be changed:
void myfunc (const Complex& c)
{ c.re = 0.2; /* ILLEGAL!! compiler error... */  }
\end{lstlisting}
If we declare the function and try to change the value to $0.2$, the compiler will complain by sending
an error message. 
If we define a function to compute the absolute value of complex variable like
\begin{lstlisting}
double Complex:: abs ()  { return sqrt(re*re + im*im);}
\end{lstlisting}
without the constant declaration  and define thereafter a function 
\verb?myabs? as
\begin{lstlisting}
double myabs (const Complex& c)
{ return c.abs(); }   // Not ok because c.abs() is not a const func.
\end{lstlisting}
the compiler would not allow the c.abs() call in myabs
since \verb?Complex::abs? is not a constant member function. 
Constant functions cannot change the object's state.
To avoid this we declare the function \verb?abs? as
\begin{lstlisting}
double Complex:: abs () const { return sqrt(re*re + im*im); } 
\end{lstlisting}

\subsubsection{Overloading operators}
C++ (and Fortran) allows  for overloading of operators. That means we can define algebraic operations
on for example vectors or any arbitrary object.   
As an example, a vector addition of the type  ${\bf c} = {\bf a} + {\bf b}$
means that we need to write   a small part of code with a for-loop over the dimension of the array.
We would rather like to write this statement as \verb?c = a+b;? as this makes the code much more
readable and close to eventual equations we want to code.  To achieve this we need to extend the definition of operators.

Let us study the declarations in our complex class.
In our main function we have a statement like \verb?d = b;?, which means
that we call \verb?d.operator= (b)? and we have defined a so-called assignment operator
as a part of the class defined as
\begin{lstlisting}
Complex& Complex:: operator= (const Complex& c)
{
   re = c.re;
   im = c.im;
   return *this;
}
\end{lstlisting}
With this function, statements like
\verb?Complex d = b;? or \verb?Complex d(b);?
make a new object $d$, which becomes a copy of $b$. 
We can make simple implementations in terms of the assignment
\begin{lstlisting}
Complex:: Complex (const Complex& c)
{ *this = c; }
\end{lstlisting}
which  is a pointer to "this object", \verb?*this? is the present object,
so \verb?*this = c;? means setting the present object equal to $c$, that is
\verb?this->operator= (c);?.



The meaning of the addition operator $+$ for complex objects is defined in the
function
\begin{lstlisting}
Complex operator+ (const Complex& a, const Complex& b); 
\end{lstlisting}
The compiler translates \verb?c = a + b;? into \verb?c = operator+ (a, b);?. 
Since this implies the call to a function, it brings in an additional overhead. If speed
is crucial and this function call is performed inside a loop, then it is more difficult for a 
given compiler to perform optimizations of a loop.
The solution to this is to inline functions.   We discussed inlining in chapter \ref{chap:numanalysis}.
Inlining means that the function body is copied directly into
the calling code, thus avoiding calling the function.
Inlining is enabled by the inline keyword
\begin{lstlisting}
inline Complex operator+ (const Complex& a, const Complex& b)
{ return Complex (a.re + b.re, a.im + b.im); }
\end{lstlisting}
Inline functions, with complete bodies must be written in the header file  complex.h.
Consider  the case \verb?c = a + b;?
that is,  \verb?c.operator= (operator+ (a,b));?
If \verb?operator+?, \verb?operator=? and the constructor \verb?Complex(r,i)? all
are inline functions, this transforms to
\begin{lstlisting}
c.re = a.re + b.re;
c.im = a.im + b.im;
\end{lstlisting}
by the compiler, i.e., no function calls

The stand-alone function \verb?operator+? is a friend of the Complex  class
\begin{lstlisting}
class Complex
{
   ...
   friend Complex operator+ (const Complex& a, const Complex& b);
   ...
};
\end{lstlisting}
so it can read (and manipulate) the private data parts $re$ and
$im$ via
\begin{lstlisting}
inline Complex operator+ (const Complex& a, const Complex& b)
{ return Complex (a.re + b.re, a.im + b.im); }
\end{lstlisting}
Since we do not need to alter the re and im variables, we can
get the values by Re() and Im(), and there is no need to be a
friend function
\begin{lstlisting}
inline Complex operator+ (const Complex& a, const Complex& b)
{ return Complex (a.Re() + b.Re(), a.Im() + b.Im()); }
\end{lstlisting}

The multiplication functionality can now be extended to imaginary numbers by the following code
\begin{lstlisting}
inline Complex operator* (const Complex& a, const Complex& b)
{
  return Complex(a.re*b.re - a.im*b.im, a.im*b.re + a.re*b.im);
}
\end{lstlisting}
It will be convenient to inline all functions used by this operator.
To inline the complete expression \verb?a*b;?, the constructors and
\verb?operator=?  must also be inlined.  This can be achieved via the following piece of code
\begin{lstlisting}
inline Complex:: Complex () { re = im = 0.0; }
inline Complex:: Complex (double re_, double im_)
{ ... }
inline Complex:: Complex (const Complex& c)
{ ... }
inline Complex:: operator= (const Complex& c)
{ ... }
// e, c, d are complex
e = c*d;
// first compiler translation:
e.operator= (operator* (c,d));
// result of nested inline functions
// operator=, operator*, Complex(double,double=0):
e.re = c.re*d.re - c.im*d.im;
e.im = c.im*d.re + c.re*d.im;
\end{lstlisting}
The definitions \verb?operator-? and \verb?operator/? follow the same setup.


Finally, if we wish to write to file or another device a complex number using the simple syntax
\verb?cout << c;?, we obtain this by defining
the effect of $<<$ for a Complex object as 
\begin{lstlisting}
ostream& operator<< (ostream& o, const Complex& c)
{ o << "(" << c.Re() << "," << c.Im() << ") "; return o;}
\end{lstlisting}

\subsubsection{Templates}

The reader may have noted that all variables and some of the functions defined in
our class are declared as doubles.  What if we wanted to make a class which takes integers
or floating point numbers with single precision?
A simple way to achieve this is copy and paste our class and replace \verb?double? with for
example \verb?int?.

C++  allows us to do this automatically via the usage of templates, which 
are the C++ constructs for parameterizing parts of
classes. Class templates  is a template for producing classes. The declaration consists
of the keyword \verb?template? followed by a list of template arguments enclosed in brackets.
We can therefore make a more general class by rewriting our original example as
\begin{lstlisting}
template<class T>
class Complex
{
private:
   T re, im; // real and imaginary part
public:
   Complex ();                              // Complex c;
   Complex (T re, T im = 0); // Definition of a complex variable;
   Complex (const Complex& c);              // Usage: Complex c(a);   // equate two complex variables
   Complex& operator= (const Complex& c); // c = a;   //  equate two complex variables, same as previous
  ~Complex () {}                        // destructor
   T   Re () const;        // T real_part = a.Re();
   T   Im () const;        // T imag_part = a.Im();
   T   abs () const;       // T m = a.abs(); // modulus
   friend Complex operator+ (const Complex&  a, const Complex& b);
   friend Complex operator- (const Complex&  a, const Complex& b);
   friend Complex operator* (const Complex&  a, const Complex& b);
   friend Complex operator/ (const Complex&  a, const Complex& b);
};
\end{lstlisting}
What it says is that \verb?Complex? is a parameterized type with $T$ as a parameter and $T$ 
has to be a type such as double
or float. 
The class complex is now a class template
and we would define variables in a code as 
\begin{lstlisting}
Complex<double> a(10.0,5.1);
Complex<int> b(1,0);
\end{lstlisting}

Member functions of our class are defined by preceding the name of the function with the \verb?template? keyword. 
Consider the function we defined as 
\begin{lstlisting}
Complex:: Complex (double re_a, double im_a)
\end{lstlisting}
We could rewrite this function as 
\begin{lstlisting}
template<class T>
Complex<T>:: Complex (T re_a, T im_a)
{ re = re_a; im = im_a; }
\end{lstlisting}
The member functions  are otherwise defined following ordinary member function definitions.


To write a class like the above is rather straightforward.  
The class for handling one-dimensional arrays, presented in the next subsection shows  
some of the additional possibilities which C++ offers. 
However, it can be rather
difficult to write good classes for handling matrices or more complex objects.  For such applications we recommend therefore the usage
of ready-made libraries like   Blitz++ or Armadillo.

Blitz++ \url{http://www.oonumerics.org/blitz/}  is a C++ library whose two main goals are
to improve the numerical efficiency of C++ and to extend the conventional dense array model 
to incorporate new and useful features. Some examples of such extensions are 
flexible storage formats, tensor notation and index placeholders.
It allows you also to write several operations involving vectors and matrices in a simple and clear
(from a mathematical point of view) way. 
The way you would code the addition of two matrices looks very similar to the way it is done
in Fortran.   From a computational point of view, a library like Armadillo 
\url{http://arma.sourceforge.net/}, which contains
much of the array functionality included in Blitz++, is preferred. Armadillo is
a C++ linear algebra library that aims towards a good balance between speed and ease of use. It includes optional
integration possibilities with popular linear algebra packages like LAPACK and BLAS, see chapter \ref{chap:linalgebra}
for further discussions.

\subsection{The vector class}
Our next next example is a very simple class to handle one-dimensional arrays.
It demonstrates again many aspects of C++
programming. However, most likely you will end up using a ready-made array class
from libraries like Blitz++ or Armadillo discussed above.  Furthermore, as was the case for the complex class, C++ contains
also its own class for one-dimensional arrays, that is a vector class. At the end however, we recommend that you use
libraries like Armadillo. 

Our class \verb?Vector? has as data a plain one-dimensional array.
We define several functions which operate on these data, from
subscripting, change of the length of the array, assignment to another vector, inner product with another vector etc etc.
To be more specific, we define the following usage of our class,that is the way the class is used in another part of the 
program:
\begin{itemize}
\item  Create vectors of a specified length defining a vector as 
\verb?Vector\ v(n);?  Via this statement we allocate space in memory for a 
vector with $n$ elements. 
\item Create a vector with zero length by writing the statement \verb?Vector v;?
\item Change the dimension of a vector $v$ to a given length $n$ by declaring
\verb?v.redim(n);?. 
Note here the way we use a function defined within a class. The function here is 
\verb?redim?.
\item
Create a vector as a copy of another vector  by simply writing 
\verb?Vector v(w);?
\item  To  extract the length of the vector by writing
\verb?const int n = v.size();?
\item To find particular value of the vector \verb?double e = v(i);?
\item or assign a number to an entry via \verb?v(j) = e;?
\item  We would also like to set two vectors equal to each other by simply writing 
\verb?w = v;?
\item  or 
take the inner product of two vectors as 
\verb?double a = w.inner(v);? or alternatively \verb?a = inner(w,v);?
\item  To write out the content of a vector could be done by via 
\verb?v.print(cout);?
\end{itemize}
This list can be made longer by adding features like vector algebra, operator overloading etc.

We present now the declaration of the class, with our comments on the various declarations. 
\begin{lstlisting}
class Vector
{
private:
  double* A;                     // vector entries
  int     length;                // the length ofthe vector
  void    allocate (int n);      // allocate memory, length=n
  void    deallocate();          // free memory
public:
  Vector ();                   // Constructor, use as Vector v;
  Vector (int n);              // use as Vector v(n);
  Vector (const Vector& w);  //  us as Vector v(w);
 ~Vector ();                   // destructor to clean up dynamic memory

  bool redim (int n);                     // change length, us as v.redim(m);
  Vector& operator= (const Vector& w);// set two vectors equal v = w;
  double  operator() (int i) const;       // a = v(i);
  double& operator() (int i);             // v(i) = a;

  void print (std::ostream& o) const;     // v.print(cout);
  double inner (const Vector& w) const; // a = v.inner(w);
  int size () const { return length; }    // n = v.size();
};
\end{lstlisting}

The class is defined via the statement \verb?class Vector?. We must first use the key word 
\verb?class?, which in turn is followed by the user-defined variable name. 
The body of the class, data and functions, is encapsulated  within the parentheses ${...};$.

Data and specific functions can be private, which means that they cannot be accessed from outside the class.
This means also that access cannot be inherited by other functions outside the class. If we use \verb?protected?
instead of \verb?private?, then data and functions can be inherited outside the class.
The key word \verb?public? means  that data and functions can be accessed from outside the class.
Here we have defined several functions  which can be accessed by functions outside the class.

The first public function we encounter is a so-called   
constructor, which  tells how we declare a variable of type \verb?Vector?
and how this variable is initialized
\begin{lstlisting}
      Vector v;   // declare a vector of length 0

      // this actually means calling the function

      Vector::Vector ()    
      { A = NULL; length = 0; }
\end{lstlisting}
The constructor is the first function that is called when an object is instantiated.
The variable \verb?A? is the vector entry which defined as a private entity. 
Here the length is set to zero.
Note also the way we define a method within the class by writing
\verb?Vector::Vector ()?. The general form is
\verb?< return type> name of class ::  name of method(<list of arguments>?.

To give our vector $v$ a dimensionality $n$ we would write 
\begin{lstlisting}
      Vector v(n);  // declare a vector of length n
      // means calling the function
      Vector::Vector (int n)
      { allocate(n); }
      void Vector::allocate (int n)
      {
        length = n;
        A = new double[n];  // create n doubles in memory
      }
\end{lstlisting}
Note that we defined a Fortran-like function for allocating memory.
This is one of nice features of C++ for Fortran programmers, one can always define
a Fortran-like world if one wishes.  
Moreover,the private function \verb?allocate? operates on the private variables
\verb?length? and \verb?A?.
A \verb?Vector? object is created (dynamically) at run time, but must 
also be destroyed when it is no longer in use. The destructor specifies how to destroy the object via the tilde
symbol shown here
\begin{lstlisting}
     Vector::~Vector ()  
     { 
       deallocate(); 
     }

     // free dynamic memory:
     void Vector::deallocate ()  
     { 
       delete [] A; 
     }
\end{lstlisting}
Again we have define a deallocation statement which mimicks the Fortran way of removing an object from
memory.
The observant reader may also have discovered that we have sneaked  in the word 'object'.
What do we mean by that?  A clarification is needed.  We will always refer to a class as
user defined and declared variable which encapsulates various data (of a given type) and operations on these
data.  An object on the other hand is an instance of a variable of a given type.
We refer to every variable we create and use as an object of a given type.  The variable \verb?A?
above is an object of type \verb?int?.
  

The function where we set two vectors to have the same 
length and have the same values can be written as  
\begin{lstlisting}
      // v and w are Vector objects
      v = w;
      // means calling
      Vector& Vector::operator= (const Vector& w)
      // for setting v = w;
      {
        redim (w.size()); // make v as long as w
        int i;
        for (i = 0; i < length; i++)  { // (C++ arrays start at 0)
          A[i] = w.A[i];   // fill in teh vector w
        }
        return *this;
      }
      // return of *this, i.e. a Vector&, allows nested  operations
      u = v = u_vec = v_vec;
\end{lstlisting}
where we have used the \verb?redim? function 
\begin{lstlisting}
      v.redim(n);  // make a vector v of length n

      bool Vector::redim (int n)
      {
        if (length == n)
          return false;  // no need to allocate anything
        else {
          if (A != NULL) {
            // "this" object has already allocated memory
            deallocate();
          }
          allocate(n);
          return true;   // the length was changed
        }
      }
\end{lstlisting}
and the copy action is defined as 
\begin{lstlisting}
      Vector v(w);  // take a copy of w

      Vector::Vector (const Vector& w)
      {
        allocate (w.size());  // "this" object gets w's length
        *this = w;            // call operator =
      }

\end{lstlisting}
Here we have defined 
\verb?this? to be  a pointer to the current (``this'') object, in other words
\verb?this? is the object itself. 
\begin{lstlisting}
void Vector::print (std::ostream& o) const
{
  int i;
  for (i = 1; i <= length; i++)
    o << "(" << i << ")=" << (*this)(i) << '\n';
}
\end{lstlisting}

\begin{lstlisting}
double a = v.inner(w);

double Vector::inner (const Vector& w) const
{
  int i; double sum = 0;
  for (i = 0; i < length; i++)  
    sum += A[i]*w.A[i];
  // alternative: 
  // for (i = 1; i <= length; i++) sum += (*this)(i)*w(i);
  return sum;
}
\end{lstlisting}

\begin{lstlisting}
// Vector v
cout << v;

ostream& operator<< (ostream& o, const Vector& v)
{ v.print(o); return o; }

// must return ostream& for nested output operators:
cout << "some text..." << w;

// this is realized by these calls:
operator<< (cout, "some text...");
operator<< (cout, w);
\end{lstlisting}

We can redefine the multiplication operator to mean the inner product of two vectors:
\begin{lstlisting}
      double a = v*w;  // example on attractive syntax

      class Vector
      { 
        ...
        // compute (*this) * w
        double operator* (const Vector& w) const;
        ...
      };

      double Vector::operator* (const Vector& w) const
      {
        return inner(w);
      }
\end{lstlisting}

\begin{lstlisting}
  // have some Vector u, v, w; double a;
  u = v + a*w;
  // global function operator+
  Vector operator+ (const Vector& a, const Vector& b)
  {
    Vector tmp(a.size());
    for (int i=1; i<=a.size(); i++)
      tmp(i) = a(i) + b(i);
    return tmp;
  }
  // global function operator*
  Vector operator* (const Vector& a, double r)
  {
    Vector tmp(a.size());
    for (int i=1; i<=a.size(); i++)
      tmp(i) = a(i)*r;
    return tmp;
  }
  // symmetric operator: r*a
  Vector operator* (double r, const Vector& a)
  { return operator*(a,r); }
\end{lstlisting}

\subsubsection{Classes and templates in C++}

We can again use templates to generalize our class to accept other types than just doubles.
To achieve that we use templates, which are the native C++ constructs for parameterizing parts of classes,
using statements like
\begin{lstlisting}
template<class T>
class Vector
{
  T* A;
  int length;
public:
  ...
  T& operator() (int i) { return A[i-1]; }
  ...
};
\end{lstlisting}
In a code which uses this class we could declare various vectors as
 Declarations in user code:
\begin{lstlisting}
Vector<double> a(10);
Vector<int> i(5);
\end{lstlisting}
where the first variable is double vector with ten elements while the second is an integer vector
with five elements.

Summarizing, it is easy to use the class \verb?Vector?
and we can hide in the class many details which are visible in C and Fortran 77 codes.  However, as you may have noted 
it is not easy to write class \verb?Vector?.
One ends often up with using ready-made classes in C++ libraries such as Blitz++ or Armadillo
unless you really need to develop your own code.
Furthermore, 
our vector class has served mainly a pedagogical scope, since 
C++ has a Standard Template Library (STL) with
vector types, including a vector for doing numerics  that can be declared as 
\begin{lstlisting}
std::valarray<double> x(n);  // vector with n entries
\end{lstlisting}
However, there is no STL for a matrix type.  
We end therefore with recommending the use of ready-made libraries like Blitz++ or Armadillo
or the matrix class discussed in the linear algebra chapter, see chapter \ref{chap:linalgebra}.

We end this section by listing the final vector class, with both header file and the definitions of the various functions.
The major part of the listing below is obvious and is not commented. The usage of the class could be as follows:
\begin{lstlisting}%[title={Usage of the Vector class}]
// Create a vector with zero length:
Vector v1;

// Redimension the vector to have length n:
int n1 = 3;
v1.redim(n1);
cout << "v1.getlength: " << v1.getLength() << endl;

// Extract the length of the vector:
const int length = v1.getLength();

// Create a vector of a specific length:
int n2 = 5;
Vector v2(n2);
cout << "v2.getlength: " << v2.getLength() << endl;

// Create a vector from an existing array:
int n3 = 3;
double* array = new double[n3];
Vector v4(n3, array);
cout << "v4.getlength: " << v4.getLength() << endl;

// Create a vector as a copy of another one:
Vector v5(v1);
cout << "v5.getlength: " << v5.getLength() << endl;

// Assign the entries in a vector:
v5(0) = 3.0;  // or alternatively v5[0] = 3.0;
v5(1) = 2.5;  // or alternatively v5[1] = 2.5;
v5(2) = 1.0;  // or alternatively v5[2] = 1.0;

// Extract the ith component of a vector:
int i = 2;
double value = v5(1);
cout << "value: " << value << endl;

// Set a vector equal another one:
Vector v6 = v5;

cout << "try redim.v6: " << v6.redim(1) << endl;
cout << "v6.getLength: " << v6.getLength() << endl;

// Take the inner product between two vectors:
double dot = v6.inner(v5); // alternatively: double dot = inner(v6,v5);
cout << "dot(v6,v5): " << dot << endl;

// Get the euclidean norm to a vector:
double norm = v6.l2norm();
cout << "norm of v6: " << norm << endl;

// Normalize a vector:
v5.normalize();

// Dump a vector to the screen:
v5.print(std::cout << "v5: " << endl);

// Arithmetic operations with vectors using a 
// syntax close to the mathematical language
Vector w = v1 + a*v2;
\end{lstlisting}
We list here the header file first.
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter03/cpp/Vector.h}}]
#ifndef VECTOR_H
#define VECTOR_H

#include <cmath>
#include <iostream>

/*****************************************************************************/
/*                            VECTOR CLASS                                   */
/*****************************************************************************/

/**
* @file   Vector.h
* @class  Vector
* @brief  Class used for manipulating one-dimensional arrays.
*
* Contains user-defined operators to do computations with arrays in a style 
* close to mathematical equations.
*
**/

class Vector{
  private:
    int length;     // Number of entries.
    double *vec;    // Entries.
    
  public:
    
    /**
    * @brief Constructor. Creates a vector initializing its elements to zero
    * @param int _length. The number of entries in the array.
    **/
    // Default constructor
    Vector();
    
    
    
    /**
    * @brief Constructor. Creates a vector initializing its elements to zero
    * @param int length. The number of entries in the array.
    **/
    // Constructor
    Vector(int _length);          
    
    
    /**
    * Constructor. Creates a vector to hold a given array.
    * @param int _length. Number of entreis in the array.
    * @param const double* a. Constant pointer to a double array.
    **/
    // Constructor
    Vector(int _length, const double *array);
    
    /**
    * Copy constructor.
		*
    **/
    // copy constructor
    Vector(const Vector&);        
    
    /**
    * Destructor.
    **/
    // Destructor
    ~Vector();                    
    
    /** Get the number of elements in an array. 
    * @return the length of the array. 
    **/
    // Get the length of the array.
    int getLength() const;
    
    // Return pointers to the data: Useful for sending data 
    // to Fortran and C
    const double* getPtr() const;
    double* getPtr();
    
    double inner(const Vector&) const;
    
    //Normalize a vector, i.e., create an unit vector
    // Normalize a vector
    void normalize();
    
    void print(std::ostream&) const;
    
    /**
    * Change the length of a vector
    **/
    bool redim(int n1);           
    
    /****************************************************/
    /*     (USER-DEFINED) OVERLOADED OPERATORS          */
    /****************************************************/
    
    // Member arithmetic operators (unary operators)
    // Vector quantities: u, v, w. Scalar: a
    
    // Copy-assignment (assignment by copy) operator
    Vector& operator =(const Vector&);  // v  = w
    
    // Add-assignment (assigment by addition) operator 
    Vector& operator+=(const Vector&);  // v += w
    
    // Substraction-assignment (assignment by substraction) operator
    Vector& operator-=(const Vector&);  // v -= w
    
    // Multiplication-assignment (assignment by multiplication) operator
    Vector& operator*=(double);         // v *= a 
    
    // Division-assignment (assignment by division) operator
    Vector& operator/=(double);         // v /= a
    
    const double& operator[](int i) const;
    double& operator[](int i);
    const double& operator()(int i) const;
    double& operator()(int i);
    bool indexOk(int i) const;
    // Get the euclidian norm (l2norm)
    double l2norm() const;
    // Unary operator +
    friend Vector operator+(const Vector&);                 // u = + v
    // Unary operator -
    friend Vector operator-(const Vector&);                 // u = - v
    /**
    * Addition of two vectors: 
    **/
    friend Vector operator+(const Vector&, const Vector&);  // u = v + w
    /**
    * Substraction of two vectors: 
    **/
    friend Vector operator-(const Vector&, const Vector&);  // u = v - w
    /**
    * Product between two vectors:
    **/
    friend Vector operator*(const Vector&, const Vector&);  // u = v * w
     /**
    * Premultiplication by a floating point number: 
    **/
    friend Vector operator*(double, const Vector&);         // u = a*v
    /**
    * Postmultiplication by a floating point number: 
    **/
    friend Vector operator*(const Vector&, double);         // u = v*a
    
    /**
    * Matrix-vector product:
    **/      
    friend Vector operator*(const Matrix&, const Vector&);  // u = A*v
              
    /**
    * Division of the entries of a vector by a scalar.
    **/
    friend Vector operator/(const Vector&, double);         // u = v/a 
    // dot product
    friend double inner(const Vector&, const Vector&);                
    
    /**
    * print the entries of a vector to screen
    **/
    friend std::ostream& operator<<(std::ostream&, const Vector&);  // cout << v
    // Note: This function does not need access to the data 
    // member. Therefore, it could have been declared as a not friend.
};

/*******************************************************************/
/*                  INLINE FUNCTIONS                               */
/*******************************************************************/

// Destructor
inline Vector::~Vector(){delete[] vec;}      

// Get the number of entries in a vector
inline int Vector::getLength() const {return length;} 

/**
* @return a constant pointer to the array of data.
* This function can be used to interface C++ with Fortran/C.
**/
inline const double* Vector::getPtr() const {return vec;}

/**
* @return a pointer to the array of data.
* This function can be used to interface C++ with Fortran/C.
**/
inline double* Vector::getPtr(){return vec; }

// Subscript. If v is an object of type Vector, the ith 
// component of v can be accessed as v[i] closer to the 
// ordinary mathematical notation instead of v.vec[i]. 
// The return value "const double&" is equivalent to
// "double", with the difference that the first approach
// is preferible when the returned object is big.
inline const double& Vector::operator[](int i) const{
  #ifdef CHECKBOUNDS_ON
  indexOk(i);
  #endif
  return vec[i];
} // read-only the ith component of the vector.
// const at the end of the function declaration means
// that the caller code can just read, not modify

// Subscript. (DANGEROUS)
inline double& Vector::operator[](int i){ 
  #ifdef CHECKBOUNDS_ON
  indexOk(i);
  #endif
  return vec[i];
} // read-write the ith coordinate


// Alternative to operator[]
inline const double& Vector::operator()(int i) const{
  #ifdef CHECKBOUNDS_ON
  indexOk(i);
  #endif
  return vec[i];
} // read-only the ith component of vec

// Subscript (DANGEROUS). If v is an object of type Vector, the ith 
// component of v can be accessed as v(i) closer to the 
// ordinary mathematical notation instead of v.vec(i). 
inline double& Vector::operator()(int i){
  #ifdef CHECKBOUNDS_ON
  indexOk(i);
  #endif
  return vec[i];
} // read-write the ith component of vec

/******************************************************************/
/*             (Arithmetic) Unary operators                       */
/******************************************************************/
// Unary operator +
inline Vector operator+(const Vector& v){     // u = + v
return v;
}

// Unary operator -
inline Vector operator-(const Vector& v){      // u = - v
return Vector(v.length) -v;
}

#endif
\end{lstlisting}
Finally, we list the source codes not included in the header file (all function which are not inlined)
\begin{lstlisting}[title={\url{http://folk.uio.no/mhjensen/compphys/programs/chapter03/cpp/Vector.cpp}}]
#include "Vector.h"

/**
* @file   Vector.cpp
* @class  Vector
* @brief  Implementation of class used for manipulating one-dimensional arrays.
**/

// default constructor
Vector::Vector(){
  length = 0;
  vec = NULL;
} 

// constructor
Vector::Vector(int _length){                
  length = _length;
  vec = new double[_length];
  for(int i=0; i<_length; i++) 
    vec[i] = 0.0;
}

// Declare the array to be constant because it is passed 
// as a pointer. Hence, it could be modified by the calling code.
Vector::Vector(int _length,         // length of the array
              const double *array){ // one-dimensioal array
  length = _length;
  vec = new double[length];
  for(int i=0; i<length; i++) 
    vec[i] = array[i];  
}

// copy constructor
Vector::Vector(const Vector& w){            
  vec = new double[length = w.length];
  for(int i=0; i<length; i++)
    vec[i] = w[i];   // This possible because we have overloaded the operator[]
  
  // A more straigforward way of implementing this constructor is:
  // vec = new double[length=w.length];
  // *this = w; // Here we use the assignment operator=
}

// normalize a vector
void Vector::normalize(){
  double tmp = 1.0/l2norm();
  for(int i=0;i<length; i++)
    vec[i] = vec[i]*tmp;    
}

void Vector::print(std::ostream& os) const{
  int i;
  for(i=0; i<length; i++){
    os << "(" << i << ") = " << vec[i] << "\n"; 
  }
}

// change the length of a vector
bool Vector::redim(int _length){
  if(length == _length)
    return false;
  else{
    if(vec != NULL){
      delete[] vec;
    }
    length = _length;
    vec = new double[length];
    return true;
  }
}

bool Vector::indexOk(int i) const{
  if(i<0 || i>=length){
    std::cerr << "vector index check; index i=" << i 
    << " out of bounds 0:" << length-1
    << std::endl;
    return false;
  }
  else
    return true;  // valid index!
}

/**********************************************************/
/*        DEFINITION OF OPERATORS                         */
/**********************************************************/
Vector& Vector::operator=(const Vector& w){   // v  = w
  if(this != &w){           // beware of self-assignment v=v
    if(length != w.length) 
      std::cout << "Bad vector sizes" << std::endl;
    for(int i=0; i<length; i++)
      vec[i] = w[i];        // closer to the mathematical notation than w.vec[i]
  }
  return *this;
} // assignment operator

Vector& Vector::operator+=(const Vector& w){  // v += w
  if(length != w.length) std::cout << "Bad vector sizes" << std::endl;
  for(int i=0; i<length; i++)
    vec[i] += w[i]; // This is possible because we have overloaded the operator[]
    return *this;
} // add a vector to the current one

Vector& Vector::operator-=(const Vector& w){  // v -= w
  if(length != w.length) std::cout << "Bad vector sizes" << std::endl;
  for(int i=0; i<length; i++)
    vec[i] -= w[i];// This possible because we have overloaded the operator[]
    return *this;
}

Vector& Vector::operator*=(double scalar){    // v *= a
  for(int i=0; i<length; i++)
    vec[i] *= scalar;
  return *this;
}

Vector& Vector::operator/=(double scalar){    // v /= a
  for(int i=0; i<length; i++)
    vec[i] /= scalar;
  return *this;
}

/******************************************************************/
/*             (Arithmetic) Binary operators                      */
/******************************************************************/

// Sum of two vectors
Vector operator+(const Vector& v, const Vector& w){ // u = v + w
  // The copy constructor checks the lengths
  return Vector(v) += w;
} // vector plus vector

// Substraction of two vectors
Vector operator-(const Vector& v, const Vector& w){ // u = v - w
  // The copy constructor checks the lengths
  return Vector(v) -= w;
} // vector minus vector

// Multiplication between two vectors
Vector operator*(const Vector& v, const Vector& w){ // u = v * w
  if(v.length != w.length) std::cout << "Bad vector sizes!" << std::endl;
  int n = v.length;
  Vector tmp(n);
  for(int i=0; i<n; i++)
    tmp[i] = v[i]*w[i];
  return tmp;  
} // vector times vector

// Postmultiplication operator
Vector operator*(const Vector& v, double scalar){   // u = v*a
  return Vector(v) *= scalar;
}

// Premultiplication operator. 
Vector operator*(double scalar, const Vector& v){   // u = a*v
  return v*scalar;  // Note the call to postmultiplication operator defined above
}

// Multiplication (product) operator: Matrix times vector
Vector operator*(const Matrix& A, const Vector& v){   // u = A*v
  int m = A.getRows();
  int n = A.getColumns();

  if(A.getColumns() != v.getLength()){
    std::cerr << "Bad sizes in: Vector operator*(const Matrix& A, const Vector& v)";
  }

  Vector u(m);
  for(int i=0; i<m; i++){
    for(int j=0; j<n; j++){
      u[i] += A[i][j]*v[j];
    }
  }
  return u;  
}

// Division of the entries in a vector by a scalar
Vector operator/(const Vector& v, double scalar){ 
  if(!scalar) std::cout << "Division by zero!" << std::endl;
  return (1.0/scalar)*v;
}

// compute the dot product between two vectors
double inner(const Vector& u, const Vector& v){       // dot product
  if(u.length != v.length){
    std::cout << "Bad vector sizes in: double inner(const Vector& u, const Vector& v)" << std::endl;
  }
  double sum = 0.0;
  for(int i=0; i<u.length; i++)
    sum += u[i]*v[i];
  return sum;
}

double Vector::inner(const Vector& v) const{        // dot product double a = u.inner(v)
  if(length != v.length)
    std::cout << "Bad vector sizes in: double Vector::inner(const Vector& v) const" << std::endl;
  double sum = 0.0;
  for(int i=0; i<v.length; i++)
    sum += vec[i]*v.vec[i];
  return sum;
}

// compute the eucledian norm
double Vector::l2norm() const{
  double norm = fabs(vec[0]);
  for(int i=1; i<length; i++){
    double vi = fabs(vec[i]);
    if(norm < 100 && vi < 100){
      norm = sqrt(norm*norm + vi*vi);
    }else if(norm > vi){    
      norm *= sqrt(1.0 + pow(vi/norm,2));
    }else{      
      norm = vi*sqrt(1.0 + pow(norm/vi,2));
    }
  }
  return norm;  
}

// dump the components of a vector to screen
std::ostream& operator<<(std::ostream& s, const Vector& v){     // output operator
  v.print(s);
  return s;
}
\end{lstlisting}

\section{Modules in Fortran}
In the previous section we discussed classes and templates in C++.
Classes offer several advantages, such as 
     \begin{itemize}
          \item Allows us to place classes into structures
          \item Pass arguments to methods
          \item Allocate storage for objects
          \item Implement associations
          \item Encapsulate internal details into classes
          \item Implement inheritance in data structures
          \end{itemize} 

Classes contain a new data type and the procedures that can be 
performed by the class. The elements (or components) of the data
type are the class data members, and the procedures are the class
member functions. In Fortran  a class is defined as a \verb?MODULE? which 
contains an abstract data \verb?TYPE? definition. 
The example we elaborate on here is a Fortran class for defining operations on single-particle
quantum numbers such as the total angular momentum, the orbital momentum, the energy, spin etc.

We present the \verb?MODULE single_particle_orbits? here and discuss several of its feature 
with links to C++ programming.
\begin{lstlisting}
!     Definition of single particle data

MODULE single_particle_orbits
  TYPE, PUBLIC :: single_particle_descript
     INTEGER :: total_orbits
     INTEGER, DIMENSION(:), POINTER :: nn, ll, jj, spin
     CHARACTER*10, DIMENSION(:), POINTER :: orbit_status, &
                                            model_space
     REAL(KIND=8), DIMENSION(:), POINTER :: e
  END TYPE single_particle_descript

  TYPE (single_particle_descript), PUBLIC :: all_orbit, &
       neutron_data, proton_data
  CONTAINS

! various member functions here 

  SUBROUTINE allocate_sp_array(this_array,n)
  TYPE (single_particle_descript), INTENT(INOUT) :: this_array
  INTEGER , INTENT(IN) :: n
  IF (ASSOCIATED (this_array%nn) ) &
     DEALLOCATE(this_array%nn)
  ALLOCATE(this_array%nn(n))
  IF (ASSOCIATED (this_array%ll) ) &
     DEALLOCATE(this_array%ll)
  ALLOCATE(this_array%ll(n))
  IF (ASSOCIATED (this_array%jj) ) &
     DEALLOCATE(this_array%jj)
  ALLOCATE(this_array%jj(n))
  IF (ASSOCIATED (this_array%spin) ) &
     DEALLOCATE(this_array%spin)
  ALLOCATE(this_array%spin(n))
  IF (ASSOCIATED (this_array%e) ) &
      DEALLOCATE(this_array%e)
  ALLOCATE(this_array%e(n))
  IF (ASSOCIATED (this_array%orbit_status) ) &
     DEALLOCATE(this_array%orbit_status)
     ALLOCATE(this_array%orbit_status(n))
  IF (ASSOCIATED (this_array%model_space) ) &
     DEALLOCATE(this_array%model_space)
     ALLOCATE(this_array%model_space(n))
! blank all characters and zero all other values
  DO i= 1, n
     this_array%model_space(i)= ' '
     this_array%orbit_status(i)= ' '
     this_array%e(i)=0.
     this_array%nn(i)=0
     this_array%ll(i)=0
     this_array%jj(i)=0
     this_array%nshell(i)=0
     this_array%itzp(i)=0
  ENDDO

  SUBROUTINE deallocate_sp_array(this_array)
   
   TYPE (single_particle_descript), INTENT(INOUT) :: this_array
   DEALLOCATE(this_array%nn) 
   DEALLOCATE(this_array%ll)
   DEALLOCATE(this_array%jj) 
   DEALLOCATE(this_array%spin)
   DEALLOCATE(this_array%e) 
   DEALLOCATE(this_array%orbit_status); &
   DEALLOCATE(this_array%model_space)
            
   END SUBROUTINE deallocate_sp_array
!
!     Read in all relevant single-particle data
!
  SUBROUTINE single_particle_data
    IMPLICIT NONE
    CHARACTER*100 ::  particle_species

    READ(5,*) particle_species
    WRITE(6,*) ' Particle species: '
    WRITE(6,*) particle_species
    SELECT CASE (particle_species)
       CASE ('electron')
          CALL read_electron_sp_data
       CASE ('proton&neutron')
          CALL read_nuclear_sp_data
    END SELECT

    END SUBROUTINE single_particle_data

END MODULE single_particle_orbits
\end{lstlisting}
The module ends with the \verb?END MODULE single_particle_orbits? statement. We have defined a public variable
\verb?  TYPE, PUBLIC :: single_particle_descript?  which plays the same role as the \verb?struct? type
in C++. In addition we have defined several  member functions which operate on various arrays and variables.

An example of a function which uses this module is given below and the module is accessed via the
\verb?USE  single_particle_orbits? statement.  

\begin{lstlisting}
! 
  PROGRAM main
  ....
  USE single_particle_orbits
  IMPLICIT NONE
  INTEGER :: i

  READ(5,*) all_orbit%total_orbits 
  IF( all_orbit%total_orbits  <= 0 ) THEN
     WRITE(6,*) 'WARNING, NO ELECTRON ORBITALS' ; STOP
  ENDIF
!     Setup all possible orbit information
!     Allocate space in heap for all single-particle data
  CALL allocate_sp_array(all_orbit,all_orbit%total_orbits) 
!     Read electron single-particle data

  DO i=1, all_orbit%total_orbits 
     READ(5,*) all_orbit%nn(i),all_orbit%ll, &
              all_orbit%jj(i),all_orbit%spin(i), &
              all_orbit%orbit_status(i), &
              all_orbit%model_space(i), all_orbit%e(i)
  ENDDO

! further instructions

  .......

! deallocate all arrays

  CALL deallocate_sp_array(all_orbit)  


  END PROGRAM main
\end{lstlisting}


Inheritance allows one to create a hierarchy of classes in which the 
base class contains the common properties of the hierarchy and the derived
classes can modify and specialize these properties. Specifically, 
a derived class contains all the class member functions of the base
class and can add new ones. Further, a derived class contains all the
class member functions of the base class and can modify them or add new
ones. The value in using inheritance is to avoid duplicating code 
when creating classes which are similar to one another.
Fortran does not support inheritance, but several features can be faked in
Fortran!  Consider the following declarations: 
\begin{lstlisting}
  TYPE proton_sp_orbit  
      TYPE (single_particle_orbits), PUBLIC :: &
           proton_particle_descript
      INTEGER, DIMENSION(:), POINTER, PUBLIC :: itzp
  END TYPE proton_sp_orbit  
\end{lstlisting}

To initialize the proton\_sp\_orbit  TYPE, we could now define
a new function
\begin{lstlisting}
  SUBROUTINE allocate_proton_array(this_array,n)

  TYPE (single_particle_descript), INTENT(INOUT) :: this_array
  INTEGER , INTENT(IN) :: n
  IF (ASSOCIATED (this_array%itzp) ) &
     DEALLOCATE(this_array%itzp)
  CALL allocate_sp_array(this_array,n) 
  this_array%itzp(i)=0

  END SUBROUTINE allocate_proton_array
\end{lstlisting}
and
\begin{lstlisting}
  SUBROUTINE dellocate_proton_array(this_array)

  TYPE (single_particle_descript), INTENT(INOUT) :: this_array
  DEALLOCATE(this_array%itzp)
  CALL deallocate_sp_array(this_array) 

  END SUBROUTINE deallocate_proton_array
\end{lstlisting}
and we could define a MODULE 
\begin{lstlisting}
  MODULE proton_class
     USE single_particle_orbits 
     TYPE proton_sp_orbit  
         TYPE (single_particle_orbits), PUBLIC :: &
              proton_particle_descript
         INTEGER, DIMENSION(:), POINTER, PUBLIC :: itzp
     END TYPE proton_sp_orbit
     INTERFACE allocate_proton
        MODULE PROCEDURE  allocate_proton_array, read_proton_array
     END INTERFACE
     INTERFACE deallocate_proton
        MODULE PROCEDURE  deallocate_proton_array
     END INTERFACE
     .....
     CONTAINS
     ....
!    various procedure
  
  END MODULE proton_class

\end{lstlisting}

\begin{lstlisting}
   PROGRAM with_just_protons
   USE proton_class
   ....
   TYPE (proton_sp_orbit ) :: proton_data
   CALL allocate_proton(proton_data)
   ....
   CALL deallocate_proton_array(prton_data)

\end{lstlisting}

We have a written a new class which contains the data of the base
class and all the procedures of the base class have been extended 
to work with the new derived class. Interface statements have to be
used to give the procedure uniform names.

We can now derive further classes for other particle types such as neutrons, hyperons etc etc. 
\section{How to make Figures with Gnuplot}\label{sec:gnuplot}
We end this chapter with a practical guide on making figures to be included in an eventual
report file.
{\bf Gnuplot} is a simple plotting program which follows the Linux/Unix 
operating system. It is easy to use and allows also to generate 
figure files which can be included in a {\bf \LaTeX} document. Here we show how to make
simple plots online and how to make postscript versions of the plot or even
a figure file which can be included in a {\bf \LaTeX} document. There are
other plotting programs such as {\bf xmgrace} as well 
which follow Linux or Unix as operating systems. An excellent alternative which many of you are familiar
with is to use Matlab to read in the data of a calculation and vizualize the results.

In order to check if gnuplot is present type
\begin{verbatim}
   which gnuplot
\end{verbatim}
If gnuplot is available, simply write 
\begin{verbatim}
   gnuplot
\end{verbatim}
to start the program. You will then see the following prompt
\begin{verbatim}
   gnuplot>
\end{verbatim}
and type help for a list of various commands and help options. 
Suppose you wish to plot data points stored in the file 
{\bf mydata.dat}. This file contains two columns of data points, where 
the first column refers
to the argument $x$ while the second one refers 
to a computed function value $f(x)$. 

If we wish to plot these sets of points with gnuplot we just need 
to write
\begin{verbatim}
   gnuplot>plot 'mydata.dat' using 1:2 w l
\end{verbatim}
or  
\begin{verbatim}
   gnuplot>plot 'mydata.dat' w l
\end{verbatim}
since gnuplot assigns as default the first column as the $x$-axis.
The abbreviations {\bf w l} stand for 'with lines'. If you prefer to plot
the data points only, write
\begin{verbatim}
   gnuplot>plot 'mydata.dat' w p
\end{verbatim}
For more plotting options, how to make axis labels etc, type help and choose
{\bf plot} as topic.

{\bf Gnuplot} will typically display a graph on the screen. If we wish to
save this graph as a postscript file, we can proceed as follows
\begin{verbatim}
   gnuplot>set terminal postscript
   gnuplot>set output 'mydata.ps'
   gnuplot>plot 'mydata.dat' w l
\end{verbatim}
and you will be the owner of a postscript file called 
{\bf mydata.ps}, which you can display with {\bf ghostview} through
the call
\begin{verbatim}
   gv mydata.ps
\end{verbatim}
 
The other alternative is to generate a figure file for the document handling
program {\bf \LaTeX}. 
The advantage here is that the text of your figure now has the same
fonts as the remaining {\bf \LaTeX} document.  
Fig.~\ref{fig:lossofprecision} was generated following the steps below.
You need to edit a file which ends with {\bf .gnu}. The file used
to generate Fig.~\ref{fig:lossofprecision} is called {\bf derivative.gnu}
and contains the following statements, which are a mix of
{\bf \LaTeX} and {\bf Gnuplot} statements. It generates a file 
{\bf derivative.tex}
which can be included in a {\bf \LaTeX} document.
Writing the following 
\begin{verbatim}
  set terminal pslatex
  set output "derivative.tex"
  set xrange [-15:0]
  set yrange [-10:8]
  set xlabel "log$_{10}(h)$"
  set ylabel "$\epsilon$"
  plot "out.dat"  title "Relative error" w l
\end{verbatim}
generates a {\bf \LaTeX} file {\bf derivative.tex}.
Alternatively, you could write the above commands in a file 
{\bf derivative.gnu} and use
{\bf Gnuplot} as follows
\begin{verbatim}
   gnuplot>load 'derivative.gnu'
\end{verbatim}

You can then include this file in a {\bf \LaTeX} document
as shown here
\begin{verbatim}
  \begin{figure}
     \begin{center}
        \input{derivative}
     \end{center}
     \caption{Log-log plot of the relative error of the second 
              derivative of $e^x$ as function of decreasing step 
              lengths $h$. The second derivative was computed for 
              $x=10$ in the program discussed above. See text for
              further details\label{fig:lossofprecision}}
   \end{figure}
\end{verbatim}
Most figures included in this text have been generated using gnuplot.
 

Many of the above commands can all be baked in a Python code.  
The following example reads a file from screen with $x$ and $y$ data, and plots these
data and saves the result as a postscript figure.
\lstset{language=python}  
\begin{lstlisting}
#!/usr/bin/env python

import sys
from Numeric import *
import Gnuplot

g = Gnuplot.Gnuplot(persist=1)

try:
    infilename = sys.argv[1]
except:
    print "Usage of this script", sys.argv[0], "infile", sys.argv[1]; sys.exit(1)
# Read file with data
ifile = open(infilename, 'r')
# Fill in x and y
x = [] ;  y = []
for line in ifile:
    pair = line.split()
    x = float(pair[0]); y = float(pair[1])
ifile.close()
# convert to a form that the gnuplot interface can deal with
d = Gnuplot.Data(x, y, title='data from output file', with='lp')
g.xlabel('log10(h)')   #  make x label
g.ylabel('log10(|Exact-Computed|)/|Exact|') 
g.plot(d)                         # plot the data
g.hardcopy(filename="relerror.ps",terminal="postscript", enhanced=1, color=1)
\end{lstlisting} 


\section{Exercises}
%\subsection*{Exercise 3.1: Computing derivatives numerically}
\begin{prob}
We want you to compute the first derivative of
\[
   f(x)=tan^{-1}(x) 
\]
for $x=\sqrt{2}$ with step lengths $h$. 
The exact answer is
$1/3$.
We want you to code the derivative using the following two
formulae 
\begin{equation}
    f'_{2c}(x)= \frac{f(x+h)-f(x)}{h}+O(h),
\label{eq:ex31a}
\end{equation}
and 
\begin{equation} 
   f'_{3c}=\frac{f_h-f_{-h}}{2h}+O(h^2),
\label{eq:ex31b}
\end{equation}
with $f_{\pm h}=f(x\pm h)$.



\begin{enumerate}
\item Find mathematical expressions for the total error due to loss
of precision and due to the numerical approximation made.
Find the step length which gives the smallest value.
Perform the analysis with both double and single precision.

\item Make thereafter a program 
which computes the first derivative using Eqs.~(\ref{eq:ex31a}) and (\ref{eq:ex31b}) 
as function of various step lengths $h$ and let $h\rightarrow 0$.
Compare with the exact answer.

Your program should contain the following elements:  
\begin{itemize}
 \item A vector (array)  which contains the step lengths. 
Use dynamic memory allocation.
 \item Vectors for the computed derivatives of Eqs.~(\ref{eq:ex31a}) and (\ref{eq:ex31b}) 
for both single and double precision.
\item A function which computes the derivative and contains call by value and reference 
(for C++ users only).

 \item Add a function which writes the results to file.
\end{itemize}
\item Compute thereafter
\[
   \epsilon=log_{10}\left(\left|\frac{f'_{\mathrm{computed}}-f'_{\mathrm{exact}}}
                 {f'_{\mathrm{exact}}}\right|\right),
\]
as function of  $log_{10}(h)$ for Eqs.~(\ref{eq:ex31a}) and (\ref{eq:ex31b})  
for both single and double precision.
Plot the results and see if you can determine empirically 
the behavior of the total error as function of $h$.
\end{enumerate}
\end{prob}


%\subsection*{prob 3.2: C++ class}
\begin{prob}
Modify your program from the previous exercise in order to include both Richardson's deferred
extrapolation algorithm from Eq.~(\ref{eq:richardsson_ext}) and Neville's interpolation algorithm
discussed in program4.cpp in this chapter. 
You will need to write a program for Richardson's algorithm.
Discuss and comment your results. 

\end{prob}


\begin{prob}
Use the results from your program for the calculation of derivatives to 
make a table of the derivatives as a function of the step length $h$. 
Write thereafter a program which reads these results and performs a numerical interpolation
using Lagrange's formula from Eq.~(\ref{eq:lagrange}) up to a polynomial of degree five.
Compare the tabulated values with those obtained using Lagrange's formula.
Compare also these results with those obtained using Neville's algorithm and comment your results. 
\end{prob}


%\subsection*{prob 3.2: C++ class}
\begin{prob}
Write your own  C++ class which allows for operations on complex variables, such as addition, subtraction, 
multiplication and division.
\end{prob}



%\subsection*{prob 3.2: C++ class}
\begin{prob}
Write a C++ class which allows for treating one-dimensional arrays for integer, real and
complex variables. Use your complex class from the previous exercise.
Use this class to perform simple vector addition and vector multiplication operations.
\end{prob}


\begin{prob}
%\subsection*{prob 3.3: C++ class}
Write a C++ class which sets up various approximations to the derivatives and repeat 
exercise 3.1 using this class.  
\end{prob}


\begin{prob}
%\subsection*{prob 3.3: C++ class}
Write a C++ class which sets up the position for a given particle in arbitrary dimensions.
Write thereafter a program which uses this class in order to set up the electron coordinates 
for the ten electrons in the neutral neon atom. This is a three-dimensional system.
Calculate also the distance $|{\bf r}_i|=\sqrt{x_i^2+y_i^2+z_i^2}$ (modulus of the position from the mass center, where the mass center is defined as the the atomic nucleus)
of a given electron $i$ to the atomic nucleus. Extend the class so that it can be used to calculate the modulus
of the relative distance between two electrons
\[
|{\bf r}_i-{\bf r}_j|=\sqrt{(x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2}.
\] 
\end{prob}


\begin{prob}
%\subsection*{prob 3.3: C++ class}
Use the class from the previous exercise to write a program which reads in the position of all planets in the solar system, using the sun as the center of mass of the system.
Let this program calculate the distance from the sun to all planets, and the relative distance between all planets.
\end{prob}


\begin{prob}
%\subsection*{prob 3.3: C++ class}
Use and extend the vector class discussed in this chapter 
to compute the 
$1$ and $2$ vector norms given by
\[
 ||{\bf x}||_1 = |x_1|+|x_2|+\dots + |x_n|,
\]
\[
||{\bf x}||_2 = (|x_1|^2+|x_2|^2+\dots + |x_n|^2)^{\frac{1}{2}}=({\bf x}^T{\bf x})^{\frac{1}{2}}.
\]
Add to the vector class the possibility to calculate an arbitrary norm $p$
\[
||{\bf x}||_p = (|x_1|^p+|x_2|^p+\dots + |x_n|^p)^{\frac{1}{p}},
\] 
where $p \ge 1$. 

Write thereafter a program which checks numerically the
the so-called Cauchy-Schwartz. For any ${\bf x}$ and ${\bf y}$ being 
real-valued or complex-valued quantities, the  inner product space satisfies
\[
   |{\bf x}^T{\bf y}| \le ||{\bf x}||_2||{\bf y}||_2,
\]
and the equality is obeyed only if ${\bf x}$ and ${\bf y}$ are linearly dependent. 
Your program
should be able to read from file two tabulated vectors, or, alternatively let the program
set them up.
\end{prob}





